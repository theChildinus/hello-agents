> æ„å»ºä¸€ä¸ªâ€œä¸“æ ç¼–å†™â€ä½œå®¶Agentç³»ç»Ÿã€‚å®ƒèƒ½é’ˆå¯¹ä¸€ä¸ªå¤§è¯é¢˜è§„åˆ’ä¸€æ•´ä¸ªä¸“æ çš„å„ä¸ªå­è¯é¢˜ï¼Œç„¶åå¯¹æ¯ä¸ªå­è¯é¢˜å±•å¼€æ–‡ç« çš„æ’°å†™ï¼›è€Œå­è¯é¢˜æ–‡ç« ä¸­çš„å„ä¸ªå°èŠ‚ä¹Ÿéœ€è¦æŒ‰ç…§ç»Ÿä¸€çš„æç¤ºè¯è¦æ±‚è¿›è¡Œé€’å½’å±•å¼€ï¼ˆè‡³å¤š3å±‚ï¼‰ï¼Œæ•´ä¸ªæ’°å†™è¿‡ç¨‹å°±åƒä¸€ç§æ ‘å½¢ç»“æ„ã€‚å…¶ä¸­è¯„å®¡Agentä¸æ˜¯ç›´æ¥ç»™å‡º"è¯„å®¡æœªé€šè¿‡"å¹¶â€œé‡è¯•â€ï¼Œè€Œæ˜¯åº”è¯¥ç»™å‡ºè¯„å®¡ç»“æœåå¯¹å†™ä½œAgentæå‡ºä¿®æ”¹å»ºè®®ï¼ŒæŠŠåŸæ–‡å’Œè¯„å®¡æ„è§ã€å»ºè®®è¿˜ç»™å†™ä½œAgentä¿®æ”¹ï¼Œè¿™ä¸ªè¿‡ç¨‹1æ¬¡å³å¯

# ä¸“æ ç¼–å†™ Agent ç³»ç»Ÿå®Œæ•´è®¾è®¡æ–¹æ¡ˆ

## ç›®å½•
- [ä¸€ã€ç³»ç»Ÿæ¦‚è¿°](#ä¸€ç³»ç»Ÿæ¦‚è¿°)
- [äºŒã€ç³»ç»Ÿæ¶æ„è®¾è®¡](#äºŒç³»ç»Ÿæ¶æ„è®¾è®¡)
- [ä¸‰ã€æ ¸å¿ƒ Agent æç¤ºè¯è®¾è®¡](#ä¸‰æ ¸å¿ƒ-agent-æç¤ºè¯è®¾è®¡)
- [å››ã€å®Œæ•´ä»£ç å®ç°](#å››å®Œæ•´ä»£ç å®ç°)
- [äº”ã€è¿›é˜¶ä¼˜åŒ–æ–¹æ¡ˆ](#äº”è¿›é˜¶ä¼˜åŒ–æ–¹æ¡ˆ)
- [å…­ã€ä½¿ç”¨ç¤ºä¾‹](#å…­ä½¿ç”¨ç¤ºä¾‹)

---

## ä¸€ã€ç³»ç»Ÿæ¦‚è¿°

### 1.1 ç³»ç»Ÿç›®æ ‡

æ„å»ºä¸€ä¸ªæ™ºèƒ½åŒ–çš„ä¸“æ å†™ä½œç³»ç»Ÿï¼Œèƒ½å¤Ÿï¼š
- é’ˆå¯¹å¤§è¯é¢˜è‡ªåŠ¨è§„åˆ’å®Œæ•´çš„ä¸“æ ç»“æ„
- æŒ‰æ ‘å½¢ç»“æ„é€’å½’å±•å¼€å„ä¸ªå­è¯é¢˜
- æ”¯æŒ3å±‚æ·±åº¦çš„å†…å®¹å±•å¼€ï¼ˆå­è¯é¢˜ â†’ å°èŠ‚ â†’ ç»†èŠ‚ï¼‰
- é€šè¿‡è¯„å®¡-ä¿®æ”¹æœºåˆ¶ä¿è¯å†…å®¹è´¨é‡

### 1.2 æ ¸å¿ƒç‰¹æ€§

- **æ ‘å½¢é€’å½’å†™ä½œ**ï¼šè‡ªé¡¶å‘ä¸‹é€å±‚å±•å¼€å†…å®¹
- **æ™ºèƒ½è¯„å®¡æœºåˆ¶**ï¼šè¯„åˆ† + è¯¦ç»†åé¦ˆ + ä¿®æ”¹å»ºè®®
- **ä¸€æ¬¡ä¿®æ”¹ç­–ç•¥**ï¼šé¿å…åå¤é‡è¯•ï¼Œæé«˜æ•ˆç‡

### 1.3 å·¥ä½œæµç¨‹å›¾

```mermaid
graph TD
    A[ç”¨æˆ·è¾“å…¥å¤§è¯é¢˜] --> B[Planner: ç”Ÿæˆä¸“æ å¤§çº²]
    B --> C[Orchestrator: éå†å­è¯é¢˜]
    C --> D[Writer: ç”Ÿæˆåˆç¨¿ Level 1]
    D --> E[Reviewer: è¯„å®¡æ‰“åˆ†]
    E --> F{è¯„åˆ†åˆ¤æ–­}
    
    F -->|â‰¥75åˆ†| G[ç›´æ¥é€šè¿‡]
    F -->|60-74åˆ†| H[Writer: æ ¹æ®å»ºè®®ä¿®æ”¹]
    F -->|<60åˆ†| I[Writer: é‡æ–°ç”Ÿæˆ]
    
    H --> J[åº”ç”¨ä¿®æ”¹]
    I --> J
    G --> K{éœ€è¦å±•å¼€å­èŠ‚ç‚¹?}
    J --> K
    
    K -->|æ˜¯,Level<3| L[é€’å½’å¤„ç†å­èŠ‚ç‚¹]
    K -->|å¦| M{è¿˜æœ‰å…¶ä»–è¯é¢˜?}
    L --> M
    
    M -->|æ˜¯| C
    M -->|å¦| N[è¾“å‡ºå®Œæ•´ä¸“æ ]
```

---

## äºŒã€ç³»ç»Ÿæ¶æ„è®¾è®¡

### 2.1 Agent è§’è‰²åˆ’åˆ†

```
ä¸“æ ç¼–å†™ç³»ç»Ÿ (Column Writing System)
â”‚
â”œâ”€â”€ ä¸»æ§ Agent (Orchestrator)
â”‚   â”œâ”€â”€ è´Ÿè´£æ•´ä½“æµç¨‹æ§åˆ¶
â”‚   â”œâ”€â”€ ç®¡ç†å„ä¸ª Agent çš„åè°ƒ
â”‚   â””â”€â”€ å¤„ç†é€’å½’é€»è¾‘
â”‚
â”œâ”€â”€ è§„åˆ’ Agent (Planner)
â”‚   â”œâ”€â”€ åˆ†æå¤§è¯é¢˜
â”‚   â”œâ”€â”€ ç”Ÿæˆä¸“æ å¤§çº²
â”‚   â””â”€â”€ è§„åˆ’å­è¯é¢˜ç»“æ„
â”‚
â”œâ”€â”€ å†™ä½œ Agent (Writer)
â”‚   â”œâ”€â”€ ç”Ÿæˆåˆç¨¿
â”‚   â”œâ”€â”€ æ ¹æ®è¯„å®¡ä¿®æ”¹å†…å®¹
â”‚   â””â”€â”€ å¤„ç†é‡å†™ä»»åŠ¡
â”‚
â””â”€â”€ è¯„å®¡ Agent (Reviewer)
    â”œâ”€â”€ è¯„ä¼°å†…å®¹è´¨é‡
    â”œâ”€â”€ æ‰“åˆ†å¹¶åˆ†çº§
    â””â”€â”€ æä¾›è¯¦ç»†ä¿®æ”¹å»ºè®®
```

### 2.2 æ•°æ®ç»“æ„è®¾è®¡

```python
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from enum import Enum

class ContentLevel(Enum):
    """å†…å®¹å±‚çº§"""
    TOPIC = 1      # å­è¯é¢˜å±‚çº§
    SECTION = 2    # å°èŠ‚å±‚çº§
    DETAIL = 3     # ç»†èŠ‚å±‚çº§

@dataclass
class ContentNode:
    """å†…å®¹æ ‘èŠ‚ç‚¹"""
    id: str                                    # èŠ‚ç‚¹å”¯ä¸€æ ‡è¯†
    title: str                                 # èŠ‚ç‚¹æ ‡é¢˜
    level: ContentLevel                        # å†…å®¹å±‚çº§
    description: str                           # èŠ‚ç‚¹æè¿°
    content: Optional[str] = None              # å®é™…å†…å®¹ï¼ˆmarkdownï¼‰
    children: List['ContentNode'] = field(default_factory=list)  # å­èŠ‚ç‚¹åˆ—è¡¨
    metadata: Dict[str, Any] = field(default_factory=dict)       # å…ƒæ•°æ®
    revision_history: List[Dict[str, Any]] = field(default_factory=list)  # ä¿®æ”¹å†å²

@dataclass  
class ReviewResult:
    """è¯„å®¡ç»“æœ"""
    score: int                                 # æ€»åˆ† (0-100)
    grade: str                                 # è¯„çº§ï¼ˆä¼˜ç§€/è‰¯å¥½/éœ€æ”¹è¿›/ä¸åˆæ ¼ï¼‰
    dimension_scores: Dict[str, int]           # å„ç»´åº¦å¾—åˆ†
    strengths: List[str]                       # ä¼˜ç‚¹åˆ—è¡¨
    issues: List[Dict[str, str]]               # é—®é¢˜åˆ—è¡¨
    revision_plan: Dict[str, Any]              # ä¿®æ”¹è®¡åˆ’
    needs_revision: bool                       # æ˜¯å¦éœ€è¦ä¿®æ”¹

@dataclass
class ColumnPlan:
    """ä¸“æ è§„åˆ’"""
    column_title: str                          # ä¸“æ æ ‡é¢˜
    column_description: str                    # ä¸“æ æè¿°
    target_audience: str                       # ç›®æ ‡è¯»è€…
    topics: List[Dict[str, Any]]               # å­è¯é¢˜åˆ—è¡¨
```

### 2.3 è´¨é‡æ§åˆ¶ç­–ç•¥

```python
class QualityControl:
    """è´¨é‡æ§åˆ¶æ ‡å‡†"""
    
    APPROVAL_THRESHOLD = 75    # ç›´æ¥é€šè¿‡åˆ†æ•°çº¿
    REVISION_THRESHOLD = 60    # ä¿®æ”¹åˆ†æ•°çº¿ï¼ˆä½äºæ­¤åˆ†æ•°é‡å†™ï¼‰
    MAX_DEPTH = 3             # æœ€å¤§é€’å½’æ·±åº¦
    
    WORD_COUNT_BY_LEVEL = {
        1: 2500,  # Level 1: å­è¯é¢˜ 2500å­—
        2: 600,   # Level 2: å°èŠ‚ 600å­—
        3: 400    # Level 3: ç»†èŠ‚ 400å­—
    }
    
    WORD_COUNT_TOLERANCE = 0.1  # å­—æ•°å…è®¸è¯¯å·® Â±10%
```

---

## ä¸‰ã€æ ¸å¿ƒ Agent æç¤ºè¯è®¾è®¡

### 3.1 è§„åˆ’ Agent (Planner)

```python
PLANNER_PROMPT = """
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸“æ ç­–åˆ’ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ä¸€ä¸ªå¤§è¯é¢˜æ‹†è§£ä¸ºç»“æ„æ¸…æ™°çš„ä¸“æ å¤§çº²ã€‚

## ä»»åŠ¡è¦æ±‚
- è¾“å…¥ï¼šå¤§è¯é¢˜ä¸»é¢˜
- è¾“å‡ºï¼šJSONæ ¼å¼çš„ä¸“æ å¤§çº²

## è¾“å‡ºæ ¼å¼
```json
{
  "column_title": "ä¸“æ æ€»æ ‡é¢˜",
  "column_description": "ä¸“æ ç®€ä»‹ï¼ˆ100-200å­—ï¼‰",
  "target_audience": "ç›®æ ‡è¯»è€…ç¾¤ä½“",
  "topics": [
    {
      "id": "topic_001",
      "title": "å­è¯é¢˜æ ‡é¢˜",
      "description": "å­è¯é¢˜ç®€ä»‹ï¼ˆ50-100å­—ï¼‰",
      "estimated_words": 2500,
      "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"],
      "prerequisites": ["å‰ç½®çŸ¥è¯†1", "å‰ç½®çŸ¥è¯†2"]
    }
  ]
}
```

## è§„åˆ’åŸåˆ™

### 1. æ•°é‡æ§åˆ¶
- å­è¯é¢˜æ•°é‡ï¼š5-10ä¸ª
- æ¯ä¸ªè¯é¢˜ç›¸å¯¹ç‹¬ç«‹ï¼Œå¯å•ç‹¬é˜…è¯»
- æ€»ä½“è¦†ç›–ä¸»é¢˜çš„å®Œæ•´çŸ¥è¯†ä½“ç³»

### 2. é€»è¾‘ç»“æ„
- **é€’è¿›å¼**ï¼šä»åŸºç¡€åˆ°é«˜çº§ï¼Œä»ç†è®ºåˆ°å®è·µ
- **å…³è”æ€§**ï¼šå‰åè¯é¢˜æœ‰é€»è¾‘è”ç³»ï¼Œå½¢æˆçŸ¥è¯†é“¾
- **å®Œæ•´æ€§**ï¼šæ¶µç›–ä¸»é¢˜çš„å„ä¸ªé‡è¦æ–¹é¢

### 3. è¯»è€…å¯¼å‘
- æ˜ç¡®ç›®æ ‡è¯»è€…çš„çŸ¥è¯†æ°´å¹³
- è®¾ç½®åˆç†çš„å­¦ä¹ æ›²çº¿
- æ¯ä¸ªè¯é¢˜éƒ½æœ‰æ˜ç¡®çš„å­¦ä¹ ç›®æ ‡

### 4. å®ç”¨æ€§
- ç†è®ºä¸å®è·µç»“åˆ
- åŒ…å«å®é™…åº”ç”¨åœºæ™¯
- æä¾›å¯æ“ä½œçš„çŸ¥è¯†å’ŒæŠ€èƒ½

## è¯é¢˜è§„åˆ’æ£€æŸ¥æ¸…å•
- [ ] æ˜¯å¦è¦†ç›–äº†ä¸»é¢˜çš„æ ¸å¿ƒæ¦‚å¿µï¼Ÿ
- [ ] æ˜¯å¦åŒ…å«å®è·µåº”ç”¨å†…å®¹ï¼Ÿ
- [ ] è¯é¢˜ä¹‹é—´çš„é¡ºåºæ˜¯å¦åˆç†ï¼Ÿ
- [ ] æ˜¯å¦é€‚åˆç›®æ ‡è¯»è€…ç¾¤ä½“ï¼Ÿ
- [ ] æ¯ä¸ªè¯é¢˜çš„èŒƒå›´æ˜¯å¦é€‚ä¸­ï¼Ÿ

ç°åœ¨ï¼Œè¯·ä¸ºä»¥ä¸‹è¯é¢˜è§„åˆ’ä¸“æ ï¼š

**ä¸»é¢˜**: {topic}

è¯·è¾“å‡ºå®Œæ•´çš„JSONæ ¼å¼ä¸“æ å¤§çº²ã€‚
"""
```

### 3.2 å†™ä½œ Agent (Writer) - åˆç¨¿ç”Ÿæˆ

```python
WRITER_PROMPT = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å†…å®¹åˆ›ä½œè€…ã€‚ä½ éœ€è¦æŒ‰ç…§æ ‘å½¢ç»“æ„é€’å½’åœ°æ’°å†™æ–‡ç« å†…å®¹ã€‚

## å½“å‰å†™ä½œä»»åŠ¡
- **å±‚çº§**: Level {level}/3
- **è¯é¢˜**: {topic_title}
- **æè¿°**: {description}
- **è¦æ±‚å­—æ•°**: {word_count} å­—ï¼ˆå…è®¸è¯¯å·®Â±10%ï¼‰
- **ä¸Šä¸‹æ–‡**: 
{context}

## å†™ä½œè¦æ±‚

### å†…å®¹ç»“æ„
{structure_requirements}

### é£æ ¼è¦æ±‚
1. **è¯­è¨€é£æ ¼**
   - æ¸…æ™°ã€ä¸“ä¸šä½†æ˜“æ‡‚
   - é¿å…è¿‡åº¦æŠ€æœ¯åŒ–çš„æœ¯è¯­å †ç Œ
   - ä½¿ç”¨ç±»æ¯”å’Œæ¯”å–»å¸®åŠ©ç†è§£

2. **æ®µè½ç»„ç»‡**
   - æ¯æ®µ3-5å¥è¯
   - ä¸»é¢˜å¥æ¸…æ™°
   - æ®µè½é—´è¿‡æ¸¡è‡ªç„¶

3. **ä¸¾ä¾‹è¯´æ˜**
   - æ¯ä¸ªå…³é”®æ¦‚å¿µé…åˆå®ä¾‹
   - ç¤ºä¾‹è¦å…·ä½“ã€å¯æ“ä½œ
   - ä»£ç ç¤ºä¾‹è¦å®Œæ•´å¯è¿è¡Œ

4. **é€»è¾‘è¿è´¯**
   - å…ˆæ€»ååˆ†
   - å¾ªåºæ¸è¿›
   - å‰åå‘¼åº”

## é€’å½’å±•å¼€è§„åˆ™

### Level {level} çš„å±•å¼€ç­–ç•¥ï¼š

**Level 1 (å­è¯é¢˜)**:
- å¿…é¡»è§„åˆ’ 3-5 ä¸ª subsections
- æ¯ä¸ª subsection æ˜¯ä¸€ä¸ªå¯ç‹¬ç«‹å±•å¼€çš„å°ä¸»é¢˜
- subsections ä¹‹é—´æœ‰é€»è¾‘é¡ºåº

**Level 2 (å°èŠ‚)**:
- æ ¹æ®å†…å®¹å¤æ‚åº¦å†³å®šæ˜¯å¦å±•å¼€
- å¦‚æœæŸä¸ªæ¦‚å¿µéœ€è¦æ·±å…¥è®²è§£ï¼Œè®¾ç½® subsections
- å»ºè®® 0-2 ä¸ª subsections

**Level 3 (ç»†èŠ‚)**:
- ä¸å†å±•å¼€ï¼ˆneeds_expansion = falseï¼‰
- ä¸“æ³¨äºå…·ä½“å†…å®¹çš„è¯¦ç»†è¯´æ˜

## è¾“å‡ºæ ¼å¼

```json
{
  "title": "ç« èŠ‚æ ‡é¢˜",
  "level": {level},
  "content": "æ­£æ–‡å†…å®¹ï¼ˆmarkdownæ ¼å¼ï¼‰",
  "word_count": å®é™…å­—æ•°,
  "needs_expansion": true/false,
  "subsections": [
    {
      "id": "section_1_1",
      "title": "å°èŠ‚æ ‡é¢˜",
      "description": "å°èŠ‚ç®€ä»‹ï¼ˆä¸€å¥è¯è¯´æ˜å†…å®¹ï¼‰",
      "estimated_words": 600,
      "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"],
      "complexity": "high/medium/low"
    }
  ],
  "metadata": {
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"],
    "references": ["å¼•ç”¨æ¥æº1", "å¼•ç”¨æ¥æº2"],
    "code_examples": ["ç¤ºä¾‹1æè¿°", "ç¤ºä¾‹2æè¿°"],
    "difficulty": "beginner/intermediate/advanced"
  }
}
```

## å±‚çº§ç»“æ„è¯¦ç»†è¦æ±‚

### Level 1 (å­è¯é¢˜çº§åˆ«) - 2500å­—å·¦å³

**ç»“æ„**:
```
1. å¼•è¨€ (200-300å­—)
   - è¯é¢˜èƒŒæ™¯
   - é‡è¦æ€§è¯´æ˜
   - æœ¬æ–‡æ¦‚è§ˆï¼ˆå‘Šè¯‰è¯»è€…å°†å­¦åˆ°ä»€ä¹ˆï¼‰

2. ä¸»ä½“å†…å®¹ (1800-2000å­—)
   åˆ†ä¸º3-5ä¸ªå°èŠ‚ï¼Œæ¯èŠ‚400-600å­—
   - å°èŠ‚1: [æ¦‚å¿µä»‹ç»]
   - å°èŠ‚2: [æ·±å…¥åˆ†æ]
   - å°èŠ‚3: [å®è·µåº”ç”¨]
   - å°èŠ‚4: [è¿›é˜¶æŠ€å·§]
   - å°èŠ‚5: [æ³¨æ„äº‹é¡¹]

3. å®è·µæ¡ˆä¾‹ (300-400å­—)
   - å®Œæ•´çš„åº”ç”¨ç¤ºä¾‹
   - ä»£ç å®ç°ï¼ˆå¦‚é€‚ç”¨ï¼‰
   - è¿è¡Œç»“æœè¯´æ˜

4. æ€»ç»“ä¸å±•æœ› (200å­—)
   - æ ¸å¿ƒè¦ç‚¹å›é¡¾
   - å»¶ä¼¸å­¦ä¹ æ–¹å‘
   - ä¸åç»­å†…å®¹çš„è”ç³»
```

**è¦ç‚¹**:
- å¿…é¡»åŒ…å« subsections å­—æ®µ
- æ¯ä¸ª subsection è¦æœ‰æ˜ç¡®çš„å­¦ä¹ ç›®æ ‡
- å†…å®¹è¦è‡ªæˆä½“ç³»ï¼Œå¯ç‹¬ç«‹é˜…è¯»

### Level 2 (å°èŠ‚çº§åˆ«) - 600å­—å·¦å³

**ç»“æ„**:
```
1. å°èŠ‚å¼•å…¥ (100å­—)
   - æ‰¿æ¥ä¸Šæ–‡
   - è¯´æ˜æœ¬èŠ‚ä¸»é¢˜

2. æ ¸å¿ƒå†…å®¹ (400å­—)
   - è¯¦ç»†è®ºè¿°æ ¸å¿ƒæ¦‚å¿µ
   - è‡³å°‘åŒ…å«1ä¸ªå…·ä½“ä¾‹å­
   - å¯¹æ¯”è¯´æ˜ï¼ˆå¦‚é€‚ç”¨ï¼‰
   - å›¾è¡¨è¾…åŠ©ï¼ˆå¦‚é€‚ç”¨ï¼‰

3. å°ç»“ (100å­—)
   - æœ¬èŠ‚è¦ç‚¹æ€»ç»“
   - å¼•å¯¼åˆ°ä¸‹ä¸€éƒ¨åˆ†
```

**è¦ç‚¹**:
- å¦‚æœå†…å®¹å¤æ‚åº¦é«˜ï¼ˆcomplexity: highï¼‰ï¼Œè®¾ç½® subsections
- ä¸“æ³¨äºæŸä¸ªå…·ä½“ä¸»é¢˜çš„æ·±å…¥è®²è§£
- ç†è®ºä¸å®è·µç»“åˆ

### Level 3 (ç»†èŠ‚çº§åˆ«) - 400å­—å·¦å³

**ç»“æ„**:
```
1. å…·ä½“è¯´æ˜ (250-300å­—)
   - æ·±å…¥æŸä¸ªç‰¹å®šç‚¹
   - è¯¦ç»†çš„æ“ä½œæ­¥éª¤æˆ–åŸç†è§£é‡Š

2. ç¤ºä¾‹æˆ–è¡¥å…… (100-150å­—)
   - ä»£ç ç‰‡æ®µ
   - å…·ä½“å®ä¾‹
   - æ³¨æ„äº‹é¡¹
```

**è¦ç‚¹**:
- needs_expansion = falseï¼ˆä¸å†å±•å¼€ï¼‰
- å†…å®¹è¦å…·ä½“ã€å¯æ“ä½œ
- é¿å…è¿‡åº¦å»¶ä¼¸

## è´¨é‡è‡ªæ£€

åœ¨ç”Ÿæˆå†…å®¹å‰ï¼Œè¯·ç¡®è®¤ï¼š
- [ ] æ˜¯å¦è¦†ç›–äº†è§„åˆ’çš„æ‰€æœ‰è¦ç‚¹ï¼Ÿ
- [ ] æ¦‚å¿µè§£é‡Šæ˜¯å¦æ¸…æ™°æ˜“æ‡‚ï¼Ÿ
- [ ] æ˜¯å¦åŒ…å«è¶³å¤Ÿçš„ä¾‹å­ï¼Ÿ
- [ ] é€»è¾‘æ˜¯å¦è¿è´¯ï¼Ÿ
- [ ] å­—æ•°æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Ÿ
- [ ] å¦‚éœ€å±•å¼€ï¼Œsubsections æ˜¯å¦è§„åˆ’åˆç†ï¼Ÿ

{additional_requirements}

ç°åœ¨å¼€å§‹æ’°å†™ï¼Œè¾“å‡ºå®Œæ•´çš„JSONæ ¼å¼å†…å®¹ã€‚
"""
```

### 3.3 è¯„å®¡ Agent (Reviewer)

```python
REVIEWER_PROMPT = """
ä½ æ˜¯ä¸€ä½ä¸¥æ ¼è€Œä¸“ä¸šçš„å†…å®¹è¯„å®¡ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯„å®¡æ–‡ç« è´¨é‡ï¼Œå¹¶æä¾›è¯¦ç»†çš„ã€å¯æ“ä½œçš„ä¿®æ”¹å»ºè®®ã€‚

## è¯„å®¡ç»´åº¦ä¸æ ‡å‡†

### 1. å†…å®¹è´¨é‡ (40åˆ†)

**å‡†ç¡®æ€§ (10åˆ†)**
- ä¿¡æ¯æ˜¯å¦å‡†ç¡®å¯é 
- æ¦‚å¿µè§£é‡Šæ˜¯å¦æ­£ç¡®
- æŠ€æœ¯ç»†èŠ‚æ˜¯å¦ç²¾ç¡®

**å®Œæ•´æ€§ (10åˆ†)**
- æ˜¯å¦è¦†ç›–äº†è§„åˆ’çš„æ‰€æœ‰è¦ç‚¹
- é€»è¾‘é“¾æ¡æ˜¯å¦å®Œæ•´
- æ˜¯å¦é—æ¼é‡è¦å†…å®¹

**æ·±åº¦ (10åˆ†)**
- åˆ†ææ˜¯å¦æ·±å…¥é€å½»
- æ˜¯å¦è§¦åŠæœ¬è´¨
- æ˜¯å¦æœ‰æ·±åˆ»æ´å¯Ÿ

**åŸåˆ›æ€§ (10åˆ†)**
- è§‚ç‚¹æ˜¯å¦æœ‰ç‹¬ç‰¹è§è§£
- è¡¨è¾¾æ˜¯å¦æœ‰æ–°æ„
- æ˜¯å¦é¿å…é™ˆè¯æ»¥è°ƒ

### 2. ç»“æ„é€»è¾‘ (30åˆ†)

**å±‚æ¬¡æ¸…æ™° (10åˆ†)**
- æ®µè½å±‚æ¬¡æ˜¯å¦åˆ†æ˜
- å°èŠ‚åˆ’åˆ†æ˜¯å¦åˆç†
- é‡ç‚¹æ˜¯å¦çªå‡º

**é€»è¾‘è¿è´¯ (10åˆ†)**
- è®ºè¿°å‰åæ˜¯å¦è¿è´¯
- å› æœå…³ç³»æ˜¯å¦æ¸…æ™°
- æ¨ç†æ˜¯å¦ä¸¥å¯†

**è¿‡æ¸¡è‡ªç„¶ (10åˆ†)**
- æ®µè½é—´è¡”æ¥æ˜¯å¦æµç•…
- ç« èŠ‚è¿‡æ¸¡æ˜¯å¦è‡ªç„¶
- æ˜¯å¦æœ‰è·³è·ƒæ„Ÿ

### 3. è¯­è¨€è¡¨è¾¾ (20åˆ†)

**æ˜“è¯»æ€§ (8åˆ†)**
- æ˜¯å¦é€šä¿—æ˜“æ‡‚
- å¥å¼æ˜¯å¦ç®€æ´
- æ˜¯å¦é¿å…å†—ä½™

**ä¸“ä¸šæ€§ (6åˆ†)**
- æœ¯è¯­ä½¿ç”¨æ˜¯å¦æ°å½“
- è¡¨è¾¾æ˜¯å¦ä¸“ä¸šè§„èŒƒ
- æ˜¯å¦ç¬¦åˆé¢†åŸŸä¹ æƒ¯

**å‡†ç¡®æ€§ (6åˆ†)**
- ç”¨è¯æ˜¯å¦ç²¾ç¡®
- è¡¨è¾¾æ˜¯å¦æ¸…æ™°æ˜ç¡®
- æ˜¯å¦æœ‰æ­§ä¹‰

### 4. æ ¼å¼è§„èŒƒ (10åˆ†)

**å­—æ•°è¾¾æ ‡ (4åˆ†)**
- æ˜¯å¦åœ¨ç›®æ ‡å­—æ•°Â±10%èŒƒå›´å†…

**æ ¼å¼æ­£ç¡® (3åˆ†)**
- Markdown æ ¼å¼æ˜¯å¦è§„èŒƒ
- ä»£ç å—æ˜¯å¦æ­£ç¡®æ ‡æ³¨
- åˆ—è¡¨æ˜¯å¦æ ¼å¼ç»Ÿä¸€

**æ’ç‰ˆç¾è§‚ (3åˆ†)**
- æ®µè½é•¿åº¦æ˜¯å¦é€‚ä¸­
- ç©ºè¡Œä½¿ç”¨æ˜¯å¦åˆç†
- æ•´ä½“æ˜¯å¦ç¾è§‚

## è¯„åˆ†æ ‡å‡†

- **ä¼˜ç§€** (85-100åˆ†): å†…å®¹æ‰å®ï¼Œè¡¨è¾¾ä¼˜ç§€ï¼Œæ— éœ€ä¿®æ”¹æˆ–ä»…éœ€å¾®è°ƒ
- **è‰¯å¥½** (75-84åˆ†): æ•´ä½“ä¸é”™ï¼Œå­˜åœ¨å¯æ”¹è¿›ä¹‹å¤„ï¼Œéœ€è¦é’ˆå¯¹æ€§ä¼˜åŒ–
- **éœ€æ”¹è¿›** (60-74åˆ†): å­˜åœ¨æ˜æ˜¾é—®é¢˜ï¼Œéœ€è¦é‡ç‚¹ä¿®æ”¹
- **ä¸åˆæ ¼** (<60åˆ†): ä¸¥é‡åç¦»è¦æ±‚ï¼Œéœ€è¦å¤§å¹…æ”¹å†™æˆ–é‡æ–°ç”Ÿæˆ

## è¯„å®¡è¾“å…¥

```json
{
  "content": "å¾…è¯„å®¡å†…å®¹ï¼ˆmarkdownæ ¼å¼ï¼‰",
  "level": å±‚çº§ (1/2/3),
  "requirements": {
    "word_count": ç›®æ ‡å­—æ•°,
    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2"],
    "structure": "ç»“æ„è¦æ±‚"
  }
}
```

## è¯„å®¡è¾“å‡ºæ ¼å¼

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºè¯„å®¡ç»“æœï¼š

```json
{
  "score": 78,
  "grade": "è‰¯å¥½",
  "dimension_scores": {
    "content_quality": 32,
    "structure": 24,
    "language": 15,
    "format": 7
  },
  "detailed_feedback": {
    "strengths": [
      "æ¦‚å¿µè§£é‡Šæ¸…æ™°ï¼Œä½¿ç”¨äº†è´´åˆ‡çš„ç±»æ¯”",
      "ä»£ç ç¤ºä¾‹å®Œæ•´å¯è¿è¡Œï¼Œæ³¨é‡Šè¯¦ç»†",
      "ç»“æ„å±‚æ¬¡åˆ†æ˜ï¼Œé€»è¾‘ä¸¥å¯†"
    ],
    "issues": [
      {
        "category": "å†…å®¹è´¨é‡",
        "severity": "ä¸­ç­‰",
        "location": "ç¬¬2æ®µï¼ˆåç¨‹æ¦‚å¿µéƒ¨åˆ†ï¼‰",
        "problem": "å¯¹åç¨‹çš„è§£é‡Šåç†è®ºï¼Œç¼ºå°‘ä¸ä¼ ç»Ÿå‡½æ•°çš„å¯¹æ¯”",
        "suggestion": "å»ºè®®æ·»åŠ ä¸€ä¸ªå¯¹æ¯”è¡¨æ ¼ï¼Œå±•ç¤ºåç¨‹ä¸æ™®é€šå‡½æ•°åœ¨æ‰§è¡Œæ–¹å¼ã€çŠ¶æ€ä¿æŒã€è°ƒç”¨æ–¹å¼ç­‰æ–¹é¢çš„åŒºåˆ«ã€‚å¯ä»¥ç”¨200å­—å·¦å³è¿›è¡Œå¯¹æ¯”è¯´æ˜ã€‚",
        "impact": "å½±å“è¯»è€…å¯¹æ ¸å¿ƒæ¦‚å¿µçš„ç†è§£"
      },
      {
        "category": "ç»“æ„é€»è¾‘",
        "severity": "è½»å¾®",
        "location": "ç¬¬3æ®µåˆ°ç¬¬4æ®µè¿‡æ¸¡",
        "problem": "ä»äº‹ä»¶å¾ªç¯ä»‹ç»ç›´æ¥è·³è½¬åˆ°async/awaitè¯­æ³•ï¼Œè¿‡æ¸¡çªå…€",
        "suggestion": "åœ¨ç¬¬3æ®µæœ«å°¾æ·»åŠ è¿‡æ¸¡å¥ï¼Œä¾‹å¦‚ï¼š'ç†è§£äº†äº‹ä»¶å¾ªç¯çš„æœºåˆ¶åï¼Œæˆ‘ä»¬æ¥çœ‹Pythonå¦‚ä½•é€šè¿‡async/awaitè¯­æ³•æ¥ç®€åŒ–å¼‚æ­¥ç¼–ç¨‹ã€‚'",
        "impact": "è½»å¾®å½±å“é˜…è¯»æµç•…åº¦"
      },
      {
        "category": "å†…å®¹å®Œæ•´æ€§",
        "severity": "ä¸¥é‡",
        "location": "å®è·µæ¡ˆä¾‹éƒ¨åˆ†ï¼ˆç¬¬5æ®µï¼‰",
        "problem": "æ‰¿è¯ºæä¾›å®Œæ•´æ¡ˆä¾‹ï¼Œä½†åªæœ‰ä»£ç ç‰‡æ®µï¼Œç¼ºå°‘åœºæ™¯è¯´æ˜å’Œè¿è¡Œç»“æœ",
        "suggestion": "è¡¥å……ä»¥ä¸‹å†…å®¹ï¼š\n1. æ¡ˆä¾‹èƒŒæ™¯è¯´æ˜ï¼ˆ100å­—ï¼‰ï¼šè¿™ä¸ªä¾‹å­è§£å†³ä»€ä¹ˆé—®é¢˜\n2. å®Œæ•´ä»£ç ï¼ˆå½“å‰åªæœ‰éƒ¨åˆ†ï¼‰\n3. è¿è¡Œç»“æœå±•ç¤ºï¼ˆ50å­—ï¼‰\n4. å…³é”®ä»£ç è§£é‡Šï¼ˆ100å­—ï¼‰",
        "impact": "ä¸¥é‡å½±å“å®è·µæŒ‡å¯¼ä»·å€¼"
      }
    ]
  },
  "revision_plan": {
    "priority_changes": [
      {
        "section": "ç¬¬2æ®µ - åç¨‹æ¦‚å¿µ",
        "action": "è¡¥å……å†…å®¹",
        "detail": "åœ¨å½“å‰è§£é‡Šåï¼Œæ·»åŠ å¯¹æ¯”è¡¨æ ¼æˆ–å¯¹æ¯”æ®µè½ï¼ˆ200å­—ï¼‰ï¼Œå¯¹æ¯”åç¨‹ä¸æ™®é€šå‡½æ•°çš„å…³é”®åŒºåˆ«ã€‚å¯ä»¥ä»ä»¥ä¸‹ç»´åº¦å¯¹æ¯”ï¼šæ‰§è¡Œæ–¹å¼ï¼ˆé¡ºåºvså¯æš‚åœï¼‰ã€çŠ¶æ€ä¿æŒï¼ˆæ˜¯vså¦ï¼‰ã€è°ƒç”¨æ–¹å¼ï¼ˆcall vs awaitï¼‰ã€é€‚ç”¨åœºæ™¯ç­‰ã€‚",
        "estimated_effort": "è¡¥å……çº¦200å­—ï¼Œéš¾åº¦ï¼šä¸­"
      },
      {
        "section": "ç¬¬5æ®µ - å®è·µæ¡ˆä¾‹",
        "action": "é‡å†™å¹¶æ‰©å……",
        "detail": "å°†å½“å‰çš„ä»£ç ç‰‡æ®µæ‰©å±•ä¸ºå®Œæ•´æ¡ˆä¾‹ï¼š\n1. æ·»åŠ æ¡ˆä¾‹èƒŒæ™¯ï¼ˆ100å­—ï¼‰ï¼šè¯´æ˜è¿™æ˜¯ä¸€ä¸ªä»€ä¹ˆåœºæ™¯ï¼Œä¸ºä»€ä¹ˆéœ€è¦å¼‚æ­¥\n2. æä¾›å®Œæ•´ä»£ç ï¼ˆç¡®ä¿å¯ç›´æ¥è¿è¡Œï¼‰\n3. å±•ç¤ºè¿è¡Œç»“æœï¼ˆ50å­—ï¼‰\n4. æ·»åŠ ä»£ç è§£é‡Šï¼ˆ100å­—ï¼‰ï¼šå…³é”®è¯­å¥çš„ä½œç”¨\næ€»è®¡éœ€è¦è¡¥å……çº¦250-300å­—",
        "estimated_effort": "è¡¥å……çº¦300å­—ï¼Œéš¾åº¦ï¼šä¸­é«˜"
      }
    ],
    "minor_improvements": [
      {
        "section": "ç¬¬3-4æ®µè¿‡æ¸¡",
        "action": "æ·»åŠ è¿‡æ¸¡å¥",
        "detail": "åœ¨ç¬¬3æ®µæœ«å°¾æ·»åŠ ï¼š'ç†è§£äº†äº‹ä»¶å¾ªç¯çš„å·¥ä½œåŸç†åï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹Pythonå¦‚ä½•é€šè¿‡async/awaitè¯­æ³•æ¥ä¼˜é›…åœ°å®ç°å¼‚æ­¥ç¼–ç¨‹ã€‚'",
        "estimated_effort": "çº¦30å­—ï¼Œéš¾åº¦ï¼šä½"
      },
      {
        "section": "ç¬¬1æ®µ - å¼•è¨€",
        "action": "è¯­è¨€ä¼˜åŒ–",
        "detail": "å°†'å¼‚æ­¥ç¼–ç¨‹éå¸¸é‡è¦'æ”¹ä¸ºæ›´å…·ä½“çš„è¡¨è¿°ï¼Œå¦‚'åœ¨å¤„ç†I/Oå¯†é›†å‹ä»»åŠ¡æ—¶ï¼Œå¼‚æ­¥ç¼–ç¨‹å¯ä»¥å°†æ€§èƒ½æå‡10-100å€'ï¼Œç”¨æ•°æ®æ”¯æ’‘é‡è¦æ€§ã€‚",
        "estimated_effort": "çº¦20å­—æ›¿æ¢ï¼Œéš¾åº¦ï¼šä½"
      }
    ]
  },
  "estimated_revision_effort": "ä¸­ç­‰ - éœ€è¦è¡¥å……çº¦500å­—å†…å®¹ï¼Œé‡å†™1ä¸ªéƒ¨åˆ†ï¼Œè°ƒæ•´2-3å¤„è¿‡æ¸¡",
  "needs_revision": true,
  "reviewer_notes": "æ–‡ç« æ•´ä½“æ¡†æ¶æ¸…æ™°ï¼Œæ¦‚å¿µè§£é‡Šè¾ƒä¸ºå‡†ç¡®ï¼Œä¸»è¦é—®é¢˜åœ¨äºå®è·µæ¡ˆä¾‹ä¸å®Œæ•´å’Œéƒ¨åˆ†è¿‡æ¸¡ä¸å¤Ÿæµç•…ã€‚å»ºè®®é‡ç‚¹è¡¥å……å®è·µæ¡ˆä¾‹éƒ¨åˆ†ï¼Œè¿™æ˜¯Level 1æ–‡ç« çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚"
}
```

## è¯„å®¡åŸåˆ™

### 1. å…·ä½“æ€§åŸåˆ™
- æ˜ç¡®æŒ‡å‡ºé—®é¢˜æ‰€åœ¨çš„å…·ä½“æ®µè½æˆ–ä½ç½®
- ç”¨å…·ä½“ä¾‹å­è¯´æ˜é—®é¢˜
- é¿å…"æ•´ä½“ä¸é”™ä½†è¿˜éœ€æ”¹è¿›"è¿™ç±»æ¨¡ç³Šè¯„ä»·

### 2. å»ºè®¾æ€§åŸåˆ™
- æ¯ä¸ªé—®é¢˜éƒ½è¦æä¾›å¯æ“ä½œçš„è§£å†³æ–¹æ¡ˆ
- è¯´æ˜å…·ä½“æ€ä¹ˆæ”¹ã€æ”¹æˆä»€ä¹ˆæ ·
- æä¾›å‚è€ƒç¤ºä¾‹æˆ–æ–¹å‘

### 3. å¹³è¡¡æ€§åŸåˆ™
- æ—¢æŒ‡å‡ºä¸è¶³ï¼Œä¹Ÿè‚¯å®šä¼˜ç‚¹
- æ ¹æ®é—®é¢˜ä¸¥é‡ç¨‹åº¦åˆ†çº§
- æä¾›ä¼˜å…ˆçº§æŒ‡å¯¼

### 4. å±‚çº§é€‚é…åŸåˆ™
- Level 1 (å­è¯é¢˜): è¯„å®¡æœ€ä¸¥æ ¼ï¼Œé‡ç‚¹å…³æ³¨å®Œæ•´æ€§å’Œæ·±åº¦
- Level 2 (å°èŠ‚): å¹³è¡¡ä¸¥æ ¼åº¦ï¼Œå…³æ³¨é’ˆå¯¹æ€§å’Œæ¸…æ™°åº¦
- Level 3 (ç»†èŠ‚): ç›¸å¯¹å®½æ¾ï¼Œå…³æ³¨å‡†ç¡®æ€§å’Œå…·ä½“æ€§

### 5. å®¢è§‚æ€§åŸåˆ™
- åŸºäºæ˜ç¡®çš„è¯„åˆ†æ ‡å‡†æ‰“åˆ†
- é¿å…ä¸»è§‚åå¥½å½±å“è¯„ä»·
- ç¡®ä¿è¯„åˆ†ä¸åé¦ˆä¸€è‡´

## å½“å‰è¯„å®¡ä»»åŠ¡

**å±‚çº§**: Level {level}
**ç›®æ ‡å­—æ•°**: {requirements[word_count]}
**å…³é”®è¦ç‚¹**: {requirements[key_points]}
**ç»“æ„è¦æ±‚**: {requirements[structure]}

**å¾…è¯„å®¡å†…å®¹**:
---
{content}
---

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ‡å‡†è¿›è¡Œè¯„å®¡ï¼Œè¾“å‡ºå®Œæ•´çš„JSONæ ¼å¼è¯„å®¡ç»“æœã€‚è®°ä½ï¼šä½ çš„è¯„å®¡æ„è§å°†ç›´æ¥ç”¨äºæŒ‡å¯¼ä¿®æ”¹ï¼Œæ‰€ä»¥å¿…é¡»å…·ä½“ã€å¯æ“ä½œã€æœ‰å»ºè®¾æ€§ã€‚
"""
```

### 3.4 ä¿®æ”¹ Agent (Revision Writer)

```python
REVISION_PROMPT = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å†…å®¹åˆ›ä½œè€…ã€‚ç°åœ¨éœ€è¦æ ¹æ®ç¼–è¾‘çš„è¯„å®¡æ„è§ä¿®æ”¹ä½ çš„æ–‡ç« ã€‚

## åŸå§‹å†…å®¹

{original_content}

## è¯„å®¡ç»“æœ

**è¯„åˆ†**: {score}/100 ({grade})

**ä¸»è¦ä¼˜ç‚¹**:
{strengths}

**å­˜åœ¨é—®é¢˜**:
{issues}

**è¯„å®¡ä¸“å®¶çš„é¢å¤–å»ºè®®**:
{reviewer_notes}

## ä¿®æ”¹è®¡åˆ’

### ä¼˜å…ˆä¿®æ”¹é¡¹ (Priority Changes)
å¿…é¡»å®Œæˆçš„ä¿®æ”¹ï¼Œç›´æ¥å½±å“å†…å®¹è´¨é‡ï¼š

{priority_changes}

### æ¬¡è¦ä¼˜åŒ–é¡¹ (Minor Improvements)
é”¦ä¸Šæ·»èŠ±çš„ä¼˜åŒ–ï¼š

{minor_improvements}

## ä¿®æ”¹è¦æ±‚

### 1. åŸºæœ¬åŸåˆ™
- **ä¿æŒä¼˜ç‚¹**: è¯„å®¡ä¸­æåˆ°çš„ä¼˜ç‚¹è¦ä¿ç•™å¹¶å‘æ‰¬
- **é’ˆå¯¹æ€§æ”¹è¿›**: ä¸¥æ ¼æŒ‰ç…§"ä¼˜å…ˆä¿®æ”¹é¡¹"è¿›è¡Œæ”¹å†™
- **æ•´ä½“è¿è´¯**: ä¿®æ”¹åè¦ç¡®ä¿å…¨æ–‡é€»è¾‘æµç•…
- **é£æ ¼ç»Ÿä¸€**: æ–°å¢å†…å®¹è¦ä¸åŸæ–‡é£æ ¼ä¸€è‡´

### 2. å­—æ•°æ§åˆ¶
- ç›®æ ‡å­—æ•°èŒƒå›´: {word_count_range}
- å½“å‰å­—æ•°: {current_word_count}
- éœ€è¦è°ƒæ•´: {word_count_adjustment}

### 3. ä¿®æ”¹æ ‡æ³¨
åœ¨ä¿®æ”¹çš„æ®µè½åä½¿ç”¨å¦‚ä¸‹æ ‡æ³¨ï¼ˆä¾›å®¡æ ¸ï¼‰ï¼š
```markdown
<!-- å·²ä¿®æ”¹: [ä¿®æ”¹ç±»å‹] - [ç®€è¦è¯´æ˜] -->
```

ç¤ºä¾‹ï¼š
```markdown
è¿™æ˜¯ä¿®æ”¹åçš„æ®µè½å†…å®¹...
<!-- å·²ä¿®æ”¹: è¡¥å……å†…å®¹ - æ·»åŠ äº†åç¨‹ä¸å‡½æ•°çš„å¯¹æ¯”è¯´æ˜ -->
```

## ä¿®æ”¹ç­–ç•¥æŒ‡å—

### è¡¥å……å†…å®¹ (Add Content)
- ç¡®å®šæ’å…¥ä½ç½®
- ä¿æŒä¸ä¸Šä¸‹æ–‡çš„è¿è´¯æ€§
- æ‹“å±•èƒŒæ™¯å’Œæ¼”è¿›

### é‡å†™éƒ¨åˆ† (Rewrite)
- ä¿ç•™æ ¸å¿ƒä¿¡æ¯
- æ”¹å–„è¡¨è¾¾æ–¹å¼
- å¢å¼ºé€»è¾‘æ€§å’Œå¯è¯»æ€§

### ä¼˜åŒ–è¯­è¨€ (Polish)
- ä½¿ç”¨æ›´ç²¾ç¡®çš„ç”¨è¯
- ç®€åŒ–å¤æ‚å¥å¼
- å¢åŠ åˆå­¦è€…/å¤–è¡Œå¯è¯»æ€§

### è°ƒæ•´ç»“æ„ (Restructure)
- é‡æ–°ç»„ç»‡æ®µè½é¡ºåº
- æ”¹å–„å†…å®¹åˆ†ç»„
- ä¼˜åŒ–æ ‡é¢˜å±‚çº§

## è¾“å‡ºæ ¼å¼

```json
{
  "revised_content": "ä¿®æ”¹åçš„å®Œæ•´å†…å®¹ï¼ˆmarkdownæ ¼å¼ï¼ŒåŒ…å«ä¿®æ”¹æ ‡æ³¨ï¼‰",
  "revision_summary": {
    "major_changes": [
      "åœ¨ç¬¬2æ®µè¡¥å……äº†åç¨‹ä¸æ™®é€šå‡½æ•°çš„å¯¹æ¯”è¡¨æ ¼ï¼ˆ200å­—ï¼‰",
      "é‡å†™äº†ç¬¬5æ®µå®è·µæ¡ˆä¾‹ï¼Œæ·»åŠ äº†åœºæ™¯è¯´æ˜ã€å®Œæ•´ä»£ç å’Œè¿è¡Œç»“æœï¼ˆ300å­—ï¼‰",
      "è°ƒæ•´äº†ç¬¬3-4æ®µè¿‡æ¸¡ï¼Œå¢å¼ºè¿è´¯æ€§"
    ],
    "minor_changes": [
      "ä¼˜åŒ–äº†ç¬¬1æ®µçš„è¡¨è¿°ï¼Œä½¿ç”¨å…·ä½“æ•°æ®æ›¿ä»£'éå¸¸é‡è¦'",
      "ç»Ÿä¸€äº†ä»£ç å—çš„æ³¨é‡Šé£æ ¼",
      "ä¿®æ­£äº†2å¤„æœ¯è¯­è¡¨è¾¾"
    ],
    "preserved_strengths": [
      "ä¿æŒäº†åŸæ–‡æ¸…æ™°çš„æ¦‚å¿µè§£é‡Šæ–¹å¼",
      "ä¿ç•™äº†æœ‰æ•ˆçš„ç±»æ¯”å’Œç¤ºä¾‹"
    ]
  },
  "word_count": ä¿®æ”¹åçš„å®é™…å­—æ•°,
  "word_count_change": "+250å­— (è¡¥å……äº†æ¡ˆä¾‹è¯´æ˜å’Œå¯¹æ¯”å†…å®¹)",
  "changes_made": {
    "sections_rewritten": ["ç¬¬5æ®µ - å®è·µæ¡ˆä¾‹"],
    "sections_expanded": ["ç¬¬2æ®µ - åç¨‹æ¦‚å¿µ"],
    "sections_polished": ["ç¬¬1æ®µ - å¼•è¨€", "ç¬¬3æ®µ - äº‹ä»¶å¾ªç¯"],
    "transitions_improved": ["ç¬¬3-4æ®µä¹‹é—´"],
    "minor_fixes": ["æœ¯è¯­ç»Ÿä¸€", "ä»£ç æ ¼å¼"]
  },
  "quality_improvements": {
    "content_completeness": "è¡¥å……äº†ç¼ºå¤±çš„æ¡ˆä¾‹è¯´æ˜å’Œå¯¹æ¯”å†…å®¹",
    "logical_flow": "æ”¹å–„äº†æ®µè½é—´è¿‡æ¸¡",
    "readability": "ä¼˜åŒ–äº†éƒ¨åˆ†è¡¨è¿°ï¼Œå¢å¼ºå¯è¯»æ€§",
    "technical_accuracy": "ç»Ÿä¸€äº†æœ¯è¯­ä½¿ç”¨"
  }
}
```

## ä¿®æ”¹è‡ªæ£€æ¸…å•

åœ¨æäº¤ä¿®æ”¹å‰ï¼Œè¯·ç¡®è®¤ï¼š

- [ ] æ‰€æœ‰"ä¼˜å…ˆä¿®æ”¹é¡¹"éƒ½å·²å®Œæˆ
- [ ] æ–°å¢å†…å®¹ä¸åŸæ–‡é£æ ¼ä¸€è‡´
- [ ] ä¿®æ”¹åçš„å†…å®¹é€»è¾‘è¿è´¯
- [ ] å­—æ•°åœ¨ç›®æ ‡èŒƒå›´å†…
- [ ] æ‰€æœ‰ä¿®æ”¹éƒ½æœ‰æ ‡æ³¨
- [ ] ä¿ç•™äº†åŸæ–‡çš„ä¼˜ç‚¹
- [ ] ä¿®æ”¹è§£å†³äº†è¯„å®¡æŒ‡å‡ºçš„é—®é¢˜
- [ ] å…¨æ–‡é€šè¯»æµç•…

## æ³¨æ„äº‹é¡¹

1. **ä¸è¦è¿‡åº¦ä¿®æ”¹**
   - åªä¿®æ”¹è¯„å®¡æŒ‡å‡ºçš„é—®é¢˜
   - å¦‚æœæŸæ®µè¯„å®¡è®¤ä¸ºå¾ˆå¥½ï¼Œå°±ä¸è¦åŠ¨
   - é¿å…"ä¸ºäº†æ”¹è€Œæ”¹"

2. **ä¿æŒåŸåˆ›æ€§**
   - è¡¥å……çš„ä¾‹å­è¦çœŸå®ã€å‡†ç¡®
   - ä¸è¦ç¼–é€ æ•°æ®æˆ–äº‹å®
   - æŠ€æœ¯å†…å®¹è¦ç¡®ä¿æ­£ç¡®æ€§

3. **å¤„ç†å†²çªå»ºè®®**
   - å¦‚æœä¿®æ”¹å»ºè®®ä¹‹é—´æœ‰çŸ›ç›¾ï¼Œä¼˜å…ˆä¿è¯å†…å®¹è´¨é‡
   - å¦‚æœæŸä¸ªå»ºè®®ä¸åˆç†ï¼Œå¯ä»¥è¯´æ˜åŸå› å¹¶é‡‡ç”¨æ›´å¥½çš„æ–¹æ¡ˆ
   - è®°å½•åœ¨ revision_summary ä¸­

4. **æ§åˆ¶ä¿®æ”¹èŒƒå›´**
   - é‡ç‚¹ä¿®æ”¹"ä¸¥é‡"å’Œ"ä¸­ç­‰"é—®é¢˜
   - "è½»å¾®"é—®é¢˜æ ¹æ®æ—¶é—´å’Œç¯‡å¹…é…Œæƒ…å¤„ç†
   - ç¡®ä¿æ ¸å¿ƒé—®é¢˜å¾—åˆ°è§£å†³

ç°åœ¨å¼€å§‹ä¿®æ”¹ï¼Œè¾“å‡ºå®Œæ•´çš„ä¿®æ”¹åå†…å®¹å’Œè¯¦ç»†çš„ä¿®æ”¹è¯´æ˜ã€‚
"""
```

---

## å››ã€å®Œæ•´ä»£ç å®ç°

### 4.1 æ ¸å¿ƒç±»å®šä¹‰

```python
import json
import asyncio
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime

class ContentLevel(Enum):
    """å†…å®¹å±‚çº§æšä¸¾"""
    TOPIC = 1      # å­è¯é¢˜
    SECTION = 2    # å°èŠ‚
    DETAIL = 3     # ç»†èŠ‚

@dataclass
class ContentNode:
    """å†…å®¹æ ‘èŠ‚ç‚¹"""
    id: str
    title: str
    level: ContentLevel
    description: str
    content: Optional[str] = None
    children: List['ContentNode'] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    revision_history: List[Dict[str, Any]] = field(default_factory=list)
    
    def add_child(self, child: 'ContentNode'):
        """æ·»åŠ å­èŠ‚ç‚¹"""
        self.children.append(child)
    
    def get_all_nodes(self) -> List['ContentNode']:
        """è·å–æ‰€æœ‰èŠ‚ç‚¹ï¼ˆæ·±åº¦ä¼˜å…ˆï¼‰"""
        nodes = [self]
        for child in self.children:
            nodes.extend(child.get_all_nodes())
        return nodes
    
    def count_words(self) -> int:
        """ç»Ÿè®¡èŠ‚ç‚¹åŠå…¶å­èŠ‚ç‚¹çš„æ€»å­—æ•°"""
        total = len(self.content) if self.content else 0
        for child in self.children:
            total += child.count_words()
        return total

@dataclass
class ReviewResult:
    """è¯„å®¡ç»“æœ"""
    score: int
    grade: str
    dimension_scores: Dict[str, int]
    detailed_feedback: Dict[str, Any]
    revision_plan: Dict[str, Any]
    needs_revision: bool
    estimated_effort: str
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ReviewResult':
        """ä»å­—å…¸åˆ›å»ºè¯„å®¡ç»“æœ"""
        return cls(
            score=data['score'],
            grade=data['grade'],
            dimension_scores=data['dimension_scores'],
            detailed_feedback=data['detailed_feedback'],
            revision_plan=data['revision_plan'],
            needs_revision=data['needs_revision'],
            estimated_effort=data.get('estimated_revision_effort', 'æœªçŸ¥')
        )

@dataclass
class ColumnPlan:
    """ä¸“æ è§„åˆ’"""
    column_title: str
    column_description: str
    target_audience: str
    topics: List[Dict[str, Any]]
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ColumnPlan':
        """ä»å­—å…¸åˆ›å»ºä¸“æ è§„åˆ’"""
        return cls(
            column_title=data['column_title'],
            column_description=data['column_description'],
            target_audience=data['target_audience'],
            topics=data['topics']
        )
    
    def get_topic_count(self) -> int:
        """è·å–è¯é¢˜æ•°é‡"""
        return len(self.topics)
```

### 4.2 ä¸»ç³»ç»Ÿå®ç°

```python
class ColumnWriterAgent:
    """ä¸“æ å†™ä½œæ™ºèƒ½ä½“ç³»ç»Ÿ"""
    
    # è´¨é‡æ§åˆ¶å¸¸é‡
    APPROVAL_THRESHOLD = 75    # ç›´æ¥é€šè¿‡åˆ†æ•°çº¿
    REVISION_THRESHOLD = 60    # ä¿®æ”¹åˆ†æ•°çº¿
    MAX_DEPTH = 3             # æœ€å¤§é€’å½’æ·±åº¦
    
    WORD_COUNT_BY_LEVEL = {
        1: 2500,
        2: 600,
        3: 400
    }
    
    def __init__(self, llm_client, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–å†™ä½œç³»ç»Ÿ
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹
            config: é…ç½®å­—å…¸ï¼Œå¯é€‰å‚æ•°ï¼š
                - approval_threshold: ç›´æ¥é€šè¿‡åˆ†æ•°çº¿ï¼ˆé»˜è®¤75ï¼‰
                - revision_threshold: ä¿®æ”¹åˆ†æ•°çº¿ï¼ˆé»˜è®¤60ï¼‰
                - max_depth: æœ€å¤§é€’å½’æ·±åº¦ï¼ˆé»˜è®¤3ï¼‰
                - enable_parallel: æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†ï¼ˆé»˜è®¤Falseï¼‰
        """
        self.llm = llm_client
        
        # åŠ è½½é…ç½®
        config = config or {}
        self.approval_threshold = config.get('approval_threshold', self.APPROVAL_THRESHOLD)
        self.revision_threshold = config.get('revision_threshold', self.REVISION_THRESHOLD)
        self.max_depth = config.get('max_depth', self.MAX_DEPTH)
        self.enable_parallel = config.get('enable_parallel', False)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_generations': 0,
            'total_reviews': 0,
            'total_revisions': 0,
            'total_rewrites': 0,
            'start_time': None,
            'end_time': None
        }
    
    async def create_column(self, main_topic: str) -> Dict[str, Any]:
        """
        åˆ›å»ºå®Œæ•´ä¸“æ 
        
        Args:
            main_topic: ä¸“æ ä¸»é¢˜
            
        Returns:
            åŒ…å«ä¸“æ å®Œæ•´ä¿¡æ¯çš„å­—å…¸
        """
        self.stats['start_time'] = datetime.now()
        
        print(f"\n{'='*70}")
        print(f"ğŸ¯ å¼€å§‹åˆ›å»ºä¸“æ ï¼š{main_topic}")
        print(f"{'='*70}\n")
        
        # Step 1: è§„åˆ’ä¸“æ ç»“æ„
        print("ğŸ“‹ ç¬¬ä¸€æ­¥ï¼šè§„åˆ’ä¸“æ ç»“æ„")
        print("-" * 70)
        column_plan = await self.plan_column(main_topic)
        print(f"âœ… ä¸“æ è§„åˆ’å®Œæˆ")
        print(f"   æ ‡é¢˜ï¼š{column_plan.column_title}")
        print(f"   è¯é¢˜æ•°ï¼š{column_plan.get_topic_count()} ä¸ª")
        print(f"   ç›®æ ‡è¯»è€…ï¼š{column_plan.target_audience}\n")
        
        # Step 2: ä¸ºæ¯ä¸ªå­è¯é¢˜åˆ›å»ºå†…å®¹æ ‘
        print("âœï¸  ç¬¬äºŒæ­¥ï¼šæ’°å†™ä¸“æ æ–‡ç« ")
        print("-" * 70)
        
        if self.enable_parallel:
            content_trees = await self._write_topics_parallel(column_plan)
        else:
            content_trees = await self._write_topics_sequential(column_plan)
        
        # Step 3: ç»„è£…å®Œæ•´ä¸“æ 
        print("\nğŸ“¦ ç¬¬ä¸‰æ­¥ï¼šç»„è£…ä¸“æ å†…å®¹")
        print("-" * 70)
        full_column = self.assemble_column(column_plan, content_trees)
        
        self.stats['end_time'] = datetime.now()
        duration = (self.stats['end_time'] - self.stats['start_time']).total_seconds()
        
        print(f"\n{'='*70}")
        print(f"âœ… ä¸“æ åˆ›å»ºå®Œæˆï¼è€—æ—¶ {duration:.1f} ç§’")
        print(f"{'='*70}\n")
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        full_column['creation_stats'] = self.stats
        
        return full_column
    
    async def _write_topics_sequential(self, column_plan: ColumnPlan) -> List[ContentNode]:
        """é¡ºåºå†™ä½œå„ä¸ªè¯é¢˜"""
        content_trees = []
        for idx, topic in enumerate(column_plan.topics, 1):
            print(f"\n{'â”€'*70}")
            print(f"ğŸ“ æ­£åœ¨å†™ä½œç¬¬ {idx}/{column_plan.get_topic_count()} ä¸ªè¯é¢˜")
            print(f"   è¯é¢˜ï¼š{topic['title']}")
            print(f"{'â”€'*70}")
            
            tree = await self.write_topic_tree(topic, column_plan)
            content_trees.append(tree)
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = idx / column_plan.get_topic_count() * 100
            print(f"\nğŸ“Š æ€»ä½“è¿›åº¦ï¼š{progress:.0f}% ({idx}/{column_plan.get_topic_count()})")
        
        return content_trees
    
    async def _write_topics_parallel(self, column_plan: ColumnPlan) -> List[ContentNode]:
        """å¹¶è¡Œå†™ä½œå„ä¸ªè¯é¢˜"""
        print("âš¡ å¯ç”¨å¹¶è¡Œæ¨¡å¼")
        tasks = [
            self.write_topic_tree(topic, column_plan)
            for topic in column_plan.topics
        ]
        content_trees = await asyncio.gather(*tasks)
        return content_trees
    
    async def plan_column(self, main_topic: str) -> ColumnPlan:
        """
        è§„åˆ’ä¸“æ å¤§çº²
        
        Args:
            main_topic: ä¸“æ ä¸»é¢˜
            
        Returns:
            ColumnPlanå®ä¾‹
        """
        prompt = PLANNER_PROMPT.format(topic=main_topic)
        response = await self.llm.generate(prompt)
        plan_data = json.loads(response)
        return ColumnPlan.from_dict(plan_data)
    
    async def write_topic_tree(
        self, 
        topic: Dict[str, Any], 
        column_context: ColumnPlan
    ) -> ContentNode:
        """
        é€’å½’å†™ä½œè¯é¢˜æ ‘
        
        Args:
            topic: è¯é¢˜ä¿¡æ¯
            column_context: ä¸“æ ä¸Šä¸‹æ–‡
            
        Returns:
            å®Œæ•´çš„å†…å®¹æ ‘æ ¹èŠ‚ç‚¹
        """
        root = ContentNode(
            id=topic['id'],
            title=topic['title'],
            level=ContentLevel.TOPIC,
            description=topic['description']
        )
        
        # é€’å½’å†™ä½œ
        context = {
            'column_title': column_context.column_title,
            'column_description': column_context.column_description,
            'target_audience': column_context.target_audience,
            'current_topic': topic
        }
        
        await self._recursive_write(root, context, level=1)
        return root
    
    async def _recursive_write(
        self, 
        node: ContentNode, 
        context: Dict[str, Any], 
        level: int
    ):
        """
        é€’å½’å†™ä½œæ ¸å¿ƒé€»è¾‘
        
        Args:
            node: å½“å‰èŠ‚ç‚¹
            context: å†™ä½œä¸Šä¸‹æ–‡
            level: å½“å‰å±‚çº§
        """
        if level > self.max_depth:
            indent = "  " * level
            print(f"{indent}âš ï¸  è¾¾åˆ°æœ€å¤§æ·±åº¦ {self.max_depth}ï¼Œåœæ­¢å±•å¼€")
            return
        
        indent = "  " * level
        print(f"\n{indent}{'â”ˆ'*40}")
        print(f"{indent}ğŸ“„ Level {level}: {node.title}")
        print(f"{indent}{'â”ˆ'*40}")
        
        # Step 1: ç”Ÿæˆåˆç¨¿
        print(f"{indent}âœï¸  ç”Ÿæˆåˆç¨¿...")
        content_data = await self._generate_content(node, context, level)
        self.stats['total_generations'] += 1
        
        original_content = content_data['content']
        word_count = content_data.get('word_count', len(original_content))
        print(f"{indent}   å­—æ•°ï¼š{word_count}")
        
        # Step 2: è¯„å®¡
        print(f"{indent}ğŸ” è¯„å®¡ä¸­...")
        review_result = await self._review_content(content_data, level, node.description, context)
        self.stats['total_reviews'] += 1
        
        score = review_result.score
        grade = review_result.grade
        print(f"{indent}ğŸ“Š è¯„å®¡ç»“æœï¼š{score}åˆ† ({grade})")
        
        # Step 3: æ ¹æ®è¯„åˆ†å†³å®šå¤„ç†ç­–ç•¥
        if score >= self.approval_threshold:
            # ç›´æ¥é€šè¿‡
            print(f"{indent}âœ… å†…å®¹ä¼˜ç§€ï¼Œç›´æ¥é€šè¿‡ï¼")
            await self._handle_approval(node, content_data, review_result)
            
        elif score >= self.revision_threshold:
            # éœ€è¦ä¿®æ”¹
            print(f"{indent}ğŸ“ éœ€è¦ä¿®æ”¹ï¼Œæ­£åœ¨ä¼˜åŒ–...")
            await self._handle_revision(node, original_content, content_data, review_result, level, context, indent)
            
        else:
            # é‡æ–°ç”Ÿæˆ
            print(f"{indent}âš ï¸  è¯„åˆ†è¿‡ä½ ({score}åˆ†)ï¼Œé‡æ–°ç”Ÿæˆ...")
            await self._handle_rewrite(node, content_data, review_result, context, level, indent)
        
        # Step 4: å¤„ç†å­èŠ‚ç‚¹
        await self._process_children(node, content_data, context, level, indent)
    
    async def _handle_approval(
        self,
        node: ContentNode,
        content_data: Dict[str, Any],
        review_result: ReviewResult
    ):
        """å¤„ç†ç›´æ¥é€šè¿‡çš„æƒ…å†µ"""
        node.content = content_data['content']
        node.metadata = content_data.get('metadata', {})
        node.metadata.update({
            'review_score': review_result.score,
            'review_grade': review_result.grade,
            'approved': True
        })
    
    async def _handle_revision(
        self,
        node: ContentNode,
        original_content: str,
        content_data: Dict[str, Any],
        review_result: ReviewResult,
        level: int,
        context: Dict[str, Any],
        indent: str
    ):
        """å¤„ç†éœ€è¦ä¿®æ”¹çš„æƒ…å†µ"""
        # æ˜¾ç¤ºä¸»è¦é—®é¢˜
        issues = review_result.detailed_feedback['issues']
        print(f"{indent}ğŸ’¡ å‘ç° {len(issues)} ä¸ªé—®é¢˜ï¼š")
        for issue in issues[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            severity_icon = {"ä¸¥é‡": "ğŸ”´", "ä¸­ç­‰": "ğŸŸ¡", "è½»å¾®": "ğŸŸ¢"}.get(issue['severity'], "âšª")
            print(f"{indent}   {severity_icon} {issue['location']}: {issue['problem'][:50]}...")
        
        # æ‰§è¡Œä¿®æ”¹
        revised_data = await self._revise_content(
            original_content,
            review_result,
            level,
            context
        )
        self.stats['total_revisions'] += 1
        
        print(f"{indent}âœ… ä¿®æ”¹å®Œæˆ")
        print(f"{indent}ğŸ“ˆ ä¸»è¦ä¿®æ”¹ï¼š")
        for change in revised_data['revision_summary']['major_changes'][:3]:
            print(f"{indent}   âœ“ {change[:60]}...")
        
        # æ›´æ–°èŠ‚ç‚¹
        node.content = revised_data['revised_content']
        node.metadata = content_data.get('metadata', {})
        node.metadata.update({
            'review_score': review_result.score,
            'review_grade': review_result.grade,
            'revised': True,
            'revision_summary': revised_data['revision_summary']
        })
        
        # è®°å½•ä¿®æ”¹å†å²
        node.revision_history.append({
            'original': original_content,
            'review': review_result.__dict__,
            'revised': revised_data['revised_content'],
            'timestamp': datetime.now().isoformat()
        })
    
    async def _handle_rewrite(
        self,
        node: ContentNode,
        content_data: Dict[str, Any],
        review_result: ReviewResult,
        context: Dict[str, Any],
        level: int,
        indent: str
    ):
        """å¤„ç†éœ€è¦é‡å†™çš„æƒ…å†µ"""
        print(f"{indent}ğŸ”„ æ­£åœ¨é‡æ–°ç”Ÿæˆ...")
        self.stats['total_rewrites'] += 1
        
        # å°†è¯„å®¡æ„è§ä½œä¸ºé¢å¤–è¦æ±‚
        additional_requirements = f"""
## ç‰¹åˆ«æ³¨æ„ï¼ˆæ ¹æ®è¯„å®¡åé¦ˆï¼‰
è¯„åˆ†è¿‡ä½çš„åŸå› ï¼š
{json.dumps(review_result.detailed_feedback['issues'], ensure_ascii=False, indent=2)}

è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹ä¿®æ”¹è®¡åˆ’ï¼š
{json.dumps(review_result.revision_plan, ensure_ascii=False, indent=2)}
"""
        
        content_data = await self._generate_content(
            node,
            context,
            level,
            additional_requirements=additional_requirements
        )
        
        node.content = content_data['content']
        node.metadata = content_data.get('metadata', {})
        node.metadata.update({
            'rewritten': True,
            'original_score': review_result.score
        })
        
        print(f"{indent}âœ… é‡æ–°ç”Ÿæˆå®Œæˆ")
    
    async def _process_children(
        self,
        node: ContentNode,
        content_data: Dict[str, Any],
        context: Dict[str, Any],
        level: int,
        indent: str
    ):
        """å¤„ç†å­èŠ‚ç‚¹"""
        if content_data.get('needs_expansion') and level < self.max_depth:
            subsections = content_data.get('subsections', [])
            if subsections:
                print(f"{indent}ğŸ“‚ éœ€è¦å±•å¼€ {len(subsections)} ä¸ªå­èŠ‚ç‚¹")
                
                for sub_idx, subsection in enumerate(subsections, 1):
                    child = ContentNode(
                        id=subsection['id'],
                        title=subsection['title'],
                        level=ContentLevel(level + 1),
                        description=subsection['description']
                    )
                    node.add_child(child)
                    
                    # é€’å½’å†™ä½œå­èŠ‚ç‚¹
                    await self._recursive_write(child, context, level + 1)
    
    async def _generate_content(
        self, 
        node: ContentNode, 
        context: Dict[str, Any], 
        level: int,
        additional_requirements: str = ""
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå†…å®¹
        
        Args:
            node: å½“å‰èŠ‚ç‚¹
            context: å†™ä½œä¸Šä¸‹æ–‡
            level: å½“å‰å±‚çº§
            additional_requirements: é¢å¤–è¦æ±‚ï¼ˆç”¨äºé‡å†™æ—¶çš„æ”¹è¿›ï¼‰
            
        Returns:
            ç”Ÿæˆçš„å†…å®¹æ•°æ®
        """
        structure_requirements = self._get_structure_requirements(level)
        
        prompt = WRITER_PROMPT.format(
            level=level,
            topic_title=node.title,
            description=node.description,
            word_count=self.WORD_COUNT_BY_LEVEL[level],
            context=json.dumps(context, ensure_ascii=False, indent=2),
            structure_requirements=structure_requirements,
            additional_requirements=additional_requirements
        )
        
        response = await self.llm.generate(prompt)
        content_data = json.loads(response)
        return content_data
    
    async def _review_content(
        self, 
        content_data: Dict[str, Any], 
        level: int,
        description: str,
        context: Dict[str, Any]
    ) -> ReviewResult:
        """
        è¯„å®¡å†…å®¹
        
        Args:
            content_data: å†…å®¹æ•°æ®
            level: å±‚çº§
            description: å†…å®¹æè¿°
            context: ä¸Šä¸‹æ–‡
            
        Returns:
            ReviewResultå®ä¾‹
        """
        requirements = {
            'word_count': self.WORD_COUNT_BY_LEVEL[level],
            'key_points': context.get('current_topic', {}).get('key_points', []),
            'structure': self._get_structure_requirements(level)
        }
        
        prompt = REVIEWER_PROMPT.format(
            level=level,
            requirements=requirements,
            content=content_data['content']
        )
        
        response = await self.llm.generate(prompt)
        review_data = json.loads(response)
        return ReviewResult.from_dict(review_data)
    
    async def _revise_content(
        self,
        original_content: str,
        review_result: ReviewResult,
        level: int,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ ¹æ®è¯„å®¡æ„è§ä¿®æ”¹å†…å®¹
        
        Args:
            original_content: åŸå§‹å†…å®¹
            review_result: è¯„å®¡ç»“æœ
            level: å±‚çº§
            context: ä¸Šä¸‹æ–‡
            
        Returns:
            ä¿®æ”¹åçš„å†…å®¹æ•°æ®
        """
        # æ ¼å¼åŒ–è¯„å®¡ä¿¡æ¯
        strengths = "\n".join([f"- {s}" for s in review_result.detailed_feedback['strengths']])
        
        issues = []
        for issue in review_result.detailed_feedback['issues']:
            issues.append(
                f"[{issue['severity']}] {issue['location']}\n"
                f"é—®é¢˜ï¼š{issue['problem']}\n"
                f"å»ºè®®ï¼š{issue['suggestion']}\n"
                f"å½±å“ï¼š{issue['impact']}"
            )
        issues_text = "\n\n".join(issues)
        
        priority_changes = "\n\n".join([
            f"{i+1}. {change['section']} - {change['action']}\n   {change['detail']}"
            for i, change in enumerate(review_result.revision_plan['priority_changes'])
        ])
        
        minor_improvements = "\n".join([
            f"- {change['section']}: {change['detail']}"
            for change in review_result.revision_plan.get('minor_improvements', [])
        ])
        
        word_count = self.WORD_COUNT_BY_LEVEL[level]
        current_word_count = len(original_content)
        word_count_range = f"{int(word_count * 0.9)}-{int(word_count * 1.1)}"
        
        # è®¡ç®—å­—æ•°è°ƒæ•´
        if current_word_count < word_count * 0.9:
            word_count_adjustment = f"éœ€è¦å¢åŠ çº¦ {int(word_count * 0.9 - current_word_count)} å­—"
        elif current_word_count > word_count * 1.1:
            word_count_adjustment = f"éœ€è¦ç²¾ç®€çº¦ {int(current_word_count - word_count * 1.1)} å­—"
        else:
            word_count_adjustment = "å­—æ•°åˆé€‚ï¼Œä¿æŒå½“å‰æ°´å¹³"
        
        reviewer_notes = review_result.__dict__.get('reviewer_notes', 'æ— ')
        
        # ç”Ÿæˆä¿®æ”¹æç¤º
        prompt = REVISION_PROMPT.format(
            original_content=original_content,
            score=review_result.score,
            grade=review_result.grade,
            strengths=strengths,
            issues=issues_text,
            reviewer_notes=reviewer_notes,
            priority_changes=priority_changes,
            minor_improvements=minor_improvements,
            word_count_range=word_count_range,
            current_word_count=current_word_count,
            word_count_adjustment=word_count_adjustment
        )
        
        response = await self.llm.generate(prompt)
        revised_data = json.loads(response)
        return revised_data
    
    def _get_structure_requirements(self, level: int) -> str:
        """è·å–å±‚çº§å¯¹åº”çš„ç»“æ„è¦æ±‚"""
        requirements = {
            1: """
Level 1 ç»“æ„ï¼ˆå­è¯é¢˜ï¼‰ï¼š
1. å¼•è¨€ï¼ˆ200-300å­—ï¼‰ï¼šèƒŒæ™¯ä»‹ç»ã€é‡è¦æ€§ã€æœ¬æ–‡æ¦‚è§ˆ
2. ä¸»ä½“å†…å®¹ï¼ˆ1800-2000å­—ï¼‰ï¼šåˆ†3-5ä¸ªå°èŠ‚ï¼Œæ¯èŠ‚400-600å­—
3. å®è·µæ¡ˆä¾‹ï¼ˆ300-400å­—ï¼‰ï¼šå®Œæ•´çš„ç¤ºä¾‹ä»£ç æˆ–åº”ç”¨åœºæ™¯
4. æ€»ç»“ä¸å±•æœ›ï¼ˆ200å­—ï¼‰ï¼šè¦ç‚¹å›é¡¾ã€å»¶ä¼¸æ€è€ƒ
            """,
            2: """
Level 2 ç»“æ„ï¼ˆå°èŠ‚ï¼‰ï¼š
1. å°èŠ‚å¼•å…¥ï¼ˆ100å­—ï¼‰ï¼šæ‰¿ä¸Šå¯ä¸‹ï¼Œè¯´æ˜æœ¬èŠ‚ä¸»é¢˜
2. æ ¸å¿ƒå†…å®¹ï¼ˆ400å­—ï¼‰ï¼šè¯¦ç»†è®ºè¿°ï¼Œè‡³å°‘åŒ…å«1ä¸ªå…·ä½“ä¾‹å­
3. å°ç»“ï¼ˆ100å­—ï¼‰ï¼šæœ¬èŠ‚è¦ç‚¹æ€»ç»“
            """,
            3: """
Level 3 ç»“æ„ï¼ˆç»†èŠ‚ï¼‰ï¼š
1. å…·ä½“è¯´æ˜ï¼ˆ250-300å­—ï¼‰ï¼šæ·±å…¥æŸä¸ªç‰¹å®šç‚¹
2. ç¤ºä¾‹æˆ–è¡¥å……ï¼ˆ100-150å­—ï¼‰ï¼šä»£ç ç‰‡æ®µæˆ–å®ä¾‹
            """
        }
        return requirements.get(level, requirements[3])
    
    def assemble_column(
        self, 
        plan: ColumnPlan, 
        trees: List[ContentNode]
    ) -> Dict[str, Any]:
        """
        ç»„è£…å®Œæ•´ä¸“æ 
        
        Args:
            plan: ä¸“æ è§„åˆ’
            trees: å†…å®¹æ ‘åˆ—è¡¨
            
        Returns:
            å®Œæ•´çš„ä¸“æ æ•°æ®
        """
        articles = []
        
        for tree in trees:
            article_content = self._tree_to_markdown(tree)
            
            articles.append({
                'id': tree.id,
                'title': tree.title,
                'content': article_content,
                'metadata': tree.metadata,
                'has_revisions': len(tree.revision_history) > 0,
                'revision_count': len(tree.revision_history),
                'word_count': tree.count_words()
            })
        
        return {
            'column_info': {
                'title': plan.column_title,
                'description': plan.column_description,
                'target_audience': plan.target_audience,
                'topic_count': plan.get_topic_count()
            },
            'articles': articles,
            'statistics': self._calculate_statistics(trees),
            'quality_report': self._generate_quality_report(trees)
        }
    
    def _tree_to_markdown(self, node: ContentNode, depth: int = 0) -> str:
        """
        å°†å†…å®¹æ ‘è½¬æ¢ä¸ºmarkdown
        
        Args:
            node: å†…å®¹èŠ‚ç‚¹
            depth: å½“å‰æ·±åº¦ï¼ˆç”¨äºæ ‡é¢˜çº§åˆ«ï¼‰
            
        Returns:
            markdownæ ¼å¼çš„å†…å®¹
        """
        markdown = []
        
        # æ ‡é¢˜
        heading_level = "#" * (depth + 1)
        markdown.append(f"{heading_level} {node.title}\n")
        
        # å†…å®¹
        if node.content:
            markdown.append(node.content)
            markdown.append("\n")
        
        # é€’å½’å¤„ç†å­èŠ‚ç‚¹
        for child in node.children:
            child_md = self._tree_to_markdown(child, depth + 1)
            markdown.append(child_md)
        
        return "\n".join(markdown)
    
    def _calculate_statistics(self, trees: List[ContentNode]) -> Dict[str, Any]:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        total_words = 0
        total_nodes = 0
        revised_nodes = 0
        rewritten_nodes = 0
        approved_nodes = 0
        
        def count_tree(node: ContentNode):
            nonlocal total_words, total_nodes, revised_nodes, rewritten_nodes, approved_nodes
            total_nodes += 1
            total_words += len(node.content) if node.content else 0
            
            if node.metadata.get('revised'):
                revised_nodes += 1
            if node.metadata.get('rewritten'):
                rewritten_nodes += 1
            if node.metadata.get('approved'):
                approved_nodes += 1
                
            for child in node.children:
                count_tree(child)
        
        for tree in trees:
            count_tree(tree)
        
        return {
            'total_articles': len(trees),
            'total_nodes': total_nodes,
            'total_words': total_words,
            'avg_words_per_article': total_words // len(trees) if trees else 0,
            'revised_nodes': revised_nodes,
            'rewritten_nodes': rewritten_nodes,
            'approved_nodes': approved_nodes,
            'revision_rate': f"{revised_nodes/total_nodes*100:.1f}%" if total_nodes > 0 else "0%",
            'approval_rate': f"{approved_nodes/total_nodes*100:.1f}%" if total_nodes > 0 else "0%"
        }
    
    def _generate_quality_report(self, trees: List[ContentNode]) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        scores = []
        grades_count = {'ä¼˜ç§€': 0, 'è‰¯å¥½': 0, 'éœ€æ”¹è¿›': 0, 'ä¸åˆæ ¼': 0}
        dimension_totals = {
            'content_quality': 0,
            'structure': 0,
            'language': 0,
            'format': 0
        }
        
        def collect_scores(node: ContentNode):
            if 'review_score' in node.metadata:
                scores.append(node.metadata['review_score'])
                grade = node.metadata.get('review_grade', 'æœªçŸ¥')
                if grade in grades_count:
                    grades_count[grade] += 1
                    
                # æ”¶é›†ç»´åº¦åˆ†æ•°
                if 'dimension_scores' in node.metadata:
                    for dim, score in node.metadata['dimension_scores'].items():
                        if dim in dimension_totals:
                            dimension_totals[dim] += score
                            
            for child in node.children:
                collect_scores(child)
        
        for tree in trees:
            collect_scores(tree)
        
        eval_count = len(scores)
        
        return {
            'average_score': sum(scores) / eval_count if scores else 0,
            'min_score': min(scores) if scores else 0,
            'max_score': max(scores) if scores else 0,
            'grade_distribution': grades_count,
            'dimension_averages': {
                dim: total / eval_count if eval_count > 0 else 0
                for dim, total in dimension_totals.items()
            },
            'total_evaluated': eval_count
        }
```

### 4.3 è¾…åŠ©å·¥å…·ç±»

```python
class ColumnExporter:
    """ä¸“æ å¯¼å‡ºå·¥å…·"""
    
    @staticmethod
    def export_to_files(column_data: Dict[str, Any], output_dir: str = "column_output"):
        """
        å¯¼å‡ºä¸“æ åˆ°æ–‡ä»¶
        
        Args:
            column_data: ä¸“æ æ•°æ®
            output_dir: è¾“å‡ºç›®å½•
        """
        import os
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # å¯¼å‡ºå®Œæ•´JSON
        json_path = os.path.join(output_dir, 'column_data.json')
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(column_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²ä¿å­˜å®Œæ•´æ•°æ®ï¼š{json_path}")
        
        # å¯¼å‡ºæ¯ç¯‡æ–‡ç« 
        for article in column_data['articles']:
            # å®‰å…¨çš„æ–‡ä»¶å
            safe_title = "".join(c for c in article['title'] if c.isalnum() or c in (' ', '-', '_')).strip()
            filename = f"{article['id']}_{safe_title}.md"
            filepath = os.path.join(output_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                # å†™å…¥æ–‡ç« å†…å®¹
                f.write(article['content'])
                
                # é™„åŠ å…ƒæ•°æ®
                f.write(f"\n\n---\n\n")
                f.write(f"## æ–‡ç« å…ƒæ•°æ®\n\n")
                f.write(f"- **æ–‡ç« ID**: {article['id']}\n")
                f.write(f"- **å­—æ•°**: {article['word_count']}\n")
                f.write(f"- **è¯„å®¡åˆ†æ•°**: {article['metadata'].get('review_score', 'N/A')}\n")
                f.write(f"- **è¯„å®¡ç­‰çº§**: {article['metadata'].get('review_grade', 'N/A')}\n")
                
                if article.get('has_revisions'):
                    f.write(f"- **ä¿®æ”¹æ¬¡æ•°**: {article['revision_count']}\n")
                    if 'revision_summary' in article['metadata']:
                        f.write(f"- **ä¸»è¦ä¿®æ”¹**:\n")
                        for change in article['metadata']['revision_summary'].get('major_changes', []):
                            f.write(f"  - {change}\n")
            
            print(f"âœ… å·²ä¿å­˜æ–‡ç« ï¼š{filepath}")
        
        # å¯¼å‡ºç»Ÿè®¡æŠ¥å‘Š
        report_path = os.path.join(output_dir, 'REPORT.md')
        ColumnExporter._export_report(column_data, report_path)
        print(f"âœ… å·²ä¿å­˜ç»Ÿè®¡æŠ¥å‘Šï¼š{report_path}")
    
    @staticmethod
    def _export_report(column_data: Dict[str, Any], filepath: str):
        """å¯¼å‡ºç»Ÿè®¡æŠ¥å‘Š"""
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"# {column_data['column_info']['title']}\n\n")
            f.write(f"## ä¸“æ ä¿¡æ¯\n\n")
            f.write(f"- **ç®€ä»‹**: {column_data['column_info']['description']}\n")
            f.write(f"- **ç›®æ ‡è¯»è€…**: {column_data['column_info']['target_audience']}\n")
            f.write(f"- **æ–‡ç« æ•°é‡**: {column_data['column_info']['topic_count']}\n\n")
            
            f.write(f"## å†…å®¹ç»Ÿè®¡\n\n")
            stats = column_data['statistics']
            f.write(f"- **æ€»å­—æ•°**: {stats['total_words']:,}\n")
            f.write(f"- **å¹³å‡æ¯ç¯‡**: {stats['avg_words_per_article']:,} å­—\n")
            f.write(f"- **å†…å®¹èŠ‚ç‚¹**: {stats['total_nodes']}\n")
            f.write(f"- **ç›´æ¥é€šè¿‡**: {stats['approved_nodes']} ({stats['approval_rate']})\n")
            f.write(f"- **ä¿®æ”¹ä¼˜åŒ–**: {stats['revised_nodes']} ({stats['revision_rate']})\n")
            f.write(f"- **é‡æ–°ç”Ÿæˆ**: {stats['rewritten_nodes']}\n\n")
            
            f.write(f"## è´¨é‡æŠ¥å‘Š\n\n")
            quality = column_data['quality_report']
            f.write(f"- **å¹³å‡åˆ†æ•°**: {quality['average_score']:.1f}/100\n")
            f.write(f"- **åˆ†æ•°èŒƒå›´**: {quality['min_score']}-{quality['max_score']}\n")
            f.write(f"- **è¯„ä¼°èŠ‚ç‚¹æ•°**: {quality['total_evaluated']}\n\n")
            
            f.write(f"### è¯„çº§åˆ†å¸ƒ\n\n")
            for grade, count in quality['grade_distribution'].items():
                if count > 0:
                    percentage = count / quality['total_evaluated'] * 100
                    f.write(f"- **{grade}**: {count} ç¯‡ ({percentage:.1f}%)\n")
            
            f.write(f"\n### å„ç»´åº¦å¹³å‡åˆ†\n\n")
            for dim, score in quality['dimension_averages'].items():
                dim_names = {
                    'content_quality': 'å†…å®¹è´¨é‡',
                    'structure': 'ç»“æ„é€»è¾‘',
                    'language': 'è¯­è¨€è¡¨è¾¾',
                    'format': 'æ ¼å¼è§„èŒƒ'
                }
                f.write(f"- **{dim_names.get(dim, dim)}**: {score:.1f}\n")
            
            # åˆ›ä½œç»Ÿè®¡
            if 'creation_stats' in column_data:
                creation = column_data['creation_stats']
                duration = (creation['end_time'] - creation['start_time']).total_seconds()
                
                f.write(f"\n## åˆ›ä½œç»Ÿè®¡\n\n")
                f.write(f"- **å¼€å§‹æ—¶é—´**: {creation['start_time'].strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"- **ç»“æŸæ—¶é—´**: {creation['end_time'].strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"- **æ€»è€—æ—¶**: {duration:.1f} ç§’ ({duration/60:.1f} åˆ†é’Ÿ)\n")
                f.write(f"- **ç”Ÿæˆæ¬¡æ•°**: {creation['total_generations']}\n")
                f.write(f"- **è¯„å®¡æ¬¡æ•°**: {creation['total_reviews']}\n")
                f.write(f"- **ä¿®æ”¹æ¬¡æ•°**: {creation['total_revisions']}\n")
                f.write(f"- **é‡å†™æ¬¡æ•°**: {creation['total_rewrites']}\n")
            
            f.write(f"\n## æ–‡ç« åˆ—è¡¨\n\n")
            for idx, article in enumerate(column_data['articles'], 1):
                f.write(f"{idx}. **{article['title']}** ({article['word_count']} å­—)\n")
                f.write(f"   - è¯„åˆ†: {article['metadata'].get('review_score', 'N/A')}/100\n")
                if article.get('has_revisions'):
                    f.write(f"   - ä¿®æ”¹: {article['revision_count']} æ¬¡\n")
                f.write("\n")


class ProgressTracker:
    """è¿›åº¦è¿½è¸ªå™¨"""
    
    def __init__(self, total_topics: int):
        self.total_topics = total_topics
        self.completed_topics = 0
        self.current_topic = None
        self.start_time = datetime.now()
    
    def start_topic(self, topic_title: str):
        """å¼€å§‹ä¸€ä¸ªè¯é¢˜"""
        self.current_topic = topic_title
        self.completed_topics += 1
        progress = self.completed_topics / self.total_topics * 100
        
        elapsed = (datetime.now() - self.start_time).total_seconds()
        avg_time = elapsed / self.completed_topics
        remaining = (self.total_topics - self.completed_topics) * avg_time
        
        print(f"\n{'='*70}")
        print(f"ğŸ“ [{self.completed_topics}/{self.total_topics}] {topic_title}")
        print(f"ğŸ“Š è¿›åº¦: {progress:.1f}%")
        print(f"â±ï¸  å·²ç”¨æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ | é¢„è®¡å‰©ä½™: {remaining/60:.1f}åˆ†é’Ÿ")
        print(f"{'='*70}")
    
    def get_summary(self) -> str:
        """è·å–æ€»ç»“"""
        total_time = (datetime.now() - self.start_time).total_seconds()
        avg_time = total_time / self.total_topics
        
        return (
            f"âœ… å…¨éƒ¨å®Œæˆï¼\n"
            f"   æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\n"
            f"   å¹³å‡æ¯ç¯‡: {avg_time/60:.1f} åˆ†é’Ÿ"
        )
```

---

## äº”ã€è¿›é˜¶ä¼˜åŒ–è¦æ±‚

### 5.1 å¹¶è¡ŒåŒ–å¤„ç†

```python
class ParallelColumnWriter(ColumnWriterAgent):
    """æ”¯æŒå¹¶è¡Œå¤„ç†çš„ä¸“æ å†™ä½œç³»ç»Ÿ"""
    
    def __init__(self, llm_client, max_concurrent: int = 3):
        """
        Args:
            llm_client: LLMå®¢æˆ·ç«¯
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
        """
        super().__init__(llm_client, config={'enable_parallel': True})
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def write_topic_tree(self, topic: Dict[str, Any], column_context: ColumnPlan) -> ContentNode:
        """å¸¦å¹¶å‘æ§åˆ¶çš„è¯é¢˜å†™ä½œ"""
        async with self.semaphore:
            return await super().write_topic_tree(topic, column_context)
    
    async def _recursive_write(self, node: ContentNode, context: Dict[str, Any], level: int):
        """å¹¶è¡Œå¤„ç†å­èŠ‚ç‚¹"""
        # å‰é¢çš„å¤„ç†é€»è¾‘ä¿æŒä¸å˜
        await super()._recursive_write(node, context, level)
        
        # å¦‚æœæœ‰å¤šä¸ªå­èŠ‚ç‚¹ï¼Œå¹¶è¡Œå¤„ç†
        if len(node.children) > 1 and level < self.max_depth:
            tasks = [
                self._recursive_write(child, context, level + 1)
                for child in node.children
            ]
            await asyncio.gather(*tasks)
```

### 5.2 äººå·¥å¹²é¢„ç‚¹

```python
class InteractiveColumnWriter(ColumnWriterAgent):
    """æ”¯æŒäººå·¥å¹²é¢„çš„ä¸“æ å†™ä½œç³»ç»Ÿ"""
    
    def __init__(self, llm_client, interactive_mode: bool = True):
        super().__init__(llm_client)
        self.interactive_mode = interactive_mode
    
    async def plan_column(self, main_topic: str) -> ColumnPlan:
        """å¸¦äººå·¥ç¡®è®¤çš„è§„åˆ’"""
        plan = await super().plan_column(main_topic)
        
        if self.interactive_mode:
            print(f"\n{'='*70}")
            print(f"ğŸ“‹ ä¸“æ è§„åˆ’é¢„è§ˆ")
            print(f"{'='*70}")
            print(f"æ ‡é¢˜: {plan.column_title}")
            print(f"ç®€ä»‹: {plan.column_description}")
            print(f"è¯é¢˜æ•°: {plan.get_topic_count()}")
            print(f"\nè¯é¢˜åˆ—è¡¨:")
            for idx, topic in enumerate(plan.topics, 1):
                print(f"  {idx}. {topic['title']}")
            
            if not await self._get_user_approval("æ˜¯å¦ç¡®è®¤æ­¤è§„åˆ’ï¼Ÿ"):
                print("\nè¯·æä¾›ä¿®æ”¹æ„è§ï¼š")
                feedback = input("> ")
                # è¿™é‡Œå¯ä»¥æ ¹æ®åé¦ˆé‡æ–°è§„åˆ’
                # plan = await self.replan_column(main_topic, feedback)
        
        return plan
    
    async def _recursive_write(self, node: ContentNode, context: Dict[str, Any], level: int):
        """å¸¦äººå·¥å®¡æ ¸çš„å†™ä½œ"""
        await super()._recursive_write(node, context, level)
        
        # åœ¨Level 1å®Œæˆåï¼Œæä¾›äººå·¥å®¡æ ¸é€‰é¡¹
        if level == 1 and self.interactive_mode:
            print(f"\nğŸ“„ æ–‡ç« ã€Š{node.title}ã€‹å·²å®Œæˆ")
            print(f"è¯„åˆ†: {node.metadata.get('review_score', 'N/A')}/100")
            
            if not await self._get_user_approval("æ˜¯å¦æ¥å—æ­¤æ–‡ç« ï¼Ÿ"):
                print("\nè¯·æä¾›ä¿®æ”¹æ„è§ï¼š")
                feedback = input("> ")
                # è¿™é‡Œå¯ä»¥æ ¹æ®åé¦ˆè¿›è¡Œé’ˆå¯¹æ€§ä¿®æ”¹
    
    async def _get_user_approval(self, prompt: str) -> bool:
        """è·å–ç”¨æˆ·ç¡®è®¤"""
        response = input(f"{prompt} (y/n): ").strip().lower()
        return response == 'y'
```

### 5.3 å¤šæ¨¡å‹åä½œ

```python
class MultiModelColumnWriter(ColumnWriterAgent):
    """å¤šæ¨¡å‹åä½œçš„ä¸“æ å†™ä½œç³»ç»Ÿ"""
    
    def __init__(self, planner_llm, writer_llm, reviewer_llm):
        """
        Args:
            planner_llm: ç”¨äºè§„åˆ’çš„æ¨¡å‹
            writer_llm: ç”¨äºå†™ä½œçš„æ¨¡å‹
            reviewer_llm: ç”¨äºè¯„å®¡çš„æ¨¡å‹
        """
        self.planner_llm = planner_llm
        self.writer_llm = writer_llm
        self.reviewer_llm = reviewer_llm
        self.max_depth = 3
        self.approval_threshold = 75
        self.revision_threshold = 60
    
    async def plan_column(self, main_topic: str) -> ColumnPlan:
        """ä½¿ç”¨ä¸“é—¨çš„è§„åˆ’æ¨¡å‹"""
        prompt = PLANNER_PROMPT.format(topic=main_topic)
        response = await self.planner_llm.generate(prompt)
        plan_data = json.loads(response)
        return ColumnPlan.from_dict(plan_data)
    
    async def _generate_content(self, node: ContentNode, context: Dict[str, Any], level: int, additional_requirements: str = "") -> Dict[str, Any]:
        """ä½¿ç”¨ä¸“é—¨çš„å†™ä½œæ¨¡å‹"""
        # ä½¿ç”¨writer_llmä»£æ›¿self.llm
        structure_requirements = self._get_structure_requirements(level)
        prompt = WRITER_PROMPT.format(
            level=level,
            topic_title=node.title,
            description=node.description,
            word_count=self.WORD_COUNT_BY_LEVEL[level],
            context=json.dumps(context, ensure_ascii=False, indent=2),
            structure_requirements=structure_requirements,
            additional_requirements=additional_requirements
        )
        response = await self.writer_llm.generate(prompt)
        return json.loads(response)
    
    async def _review_content(self, content_data: Dict[str, Any], level: int, description: str, context: Dict[str, Any]) -> ReviewResult:
        """ä½¿ç”¨ä¸“é—¨çš„è¯„å®¡æ¨¡å‹"""
        # ä½¿ç”¨reviewer_llm
        requirements = {
            'word_count': self.WORD_COUNT_BY_LEVEL[level],
            'key_points': context.get('current_topic', {}).get('key_points', []),
            'structure': self._get_structure_requirements(level)
        }
        prompt = REVIEWER_PROMPT.format(
            level=level,
            requirements=requirements,
            content=content_data['content']
        )
        response = await self.reviewer_llm.generate(prompt)
        review_data = json.loads(response)
        return ReviewResult.from_dict(review_data)
```

---

## å…­ã€ä½¿ç”¨ç¤ºä¾‹

### 6.1 åŸºç¡€ä½¿ç”¨

```python
import asyncio
from your_llm_library import LLMClient

async def basic_example():
    """åŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""
    
    # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
    llm_client = LLMClient(
        model="gpt-4",
        temperature=0.7,
        max_tokens=4000
    )
    
    # åˆ›å»ºå†™ä½œç³»ç»Ÿ
    writer = ColumnWriterAgent(llm_client)
    
    # åˆ›å»ºä¸“æ 
    result = await writer.create_column(
        main_topic="Pythonå¼‚æ­¥ç¼–ç¨‹å®Œå…¨æŒ‡å—"
    )
    
    # å¯¼å‡ºç»“æœ
    ColumnExporter.export_to_files(result)
    
    # æ‰“å°ç»Ÿè®¡
    print(f"\n{'='*70}")
    print(f"ğŸ“Š åˆ›ä½œç»Ÿè®¡")
    print(f"{'='*70}")
    stats = result['statistics']
    print(f"æ–‡ç« æ€»æ•°: {stats['total_articles']}")
    print(f"æ€»å­—æ•°: {stats['total_words']:,}")
    print(f"ç›´æ¥é€šè¿‡ç‡: {stats['approval_rate']}")
    print(f"ä¿®æ”¹ç‡: {stats['revision_rate']}")

if __name__ == "__main__":
    asyncio.run(basic_example())
```

### 6.2 è‡ªå®šä¹‰é…ç½®

```python
async def custom_config_example():
    """è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹"""
    
    llm_client = LLMClient(model="gpt-4")
    
    # è‡ªå®šä¹‰è´¨é‡æ ‡å‡†
    config = {
        'approval_threshold': 80,   # æé«˜é€šè¿‡æ ‡å‡†
        'revision_threshold': 65,   # æé«˜ä¿®æ”¹æ ‡å‡†
        'max_depth': 2,            # åªå±•å¼€2å±‚
        'enable_parallel': True     # å¯ç”¨å¹¶è¡Œ
    }
    
    writer = ColumnWriterAgent(llm_client, config=config)
    result = await writer.create_column("æ·±åº¦å­¦ä¹ å…¥é—¨")
    
    ColumnExporter.export_to_files(result, output_dir="dl_column")

if __name__ == "__main__":
    asyncio.run(custom_config_example())
```

### 6.3 ä½¿ç”¨ç¼“å­˜

```python
async def cached_example():
    """ä½¿ç”¨ç¼“å­˜ç¤ºä¾‹"""
    
    llm_client = LLMClient(model="gpt-4")
    cache = ContentCache(backend='memory')
    
    writer = CachedColumnWriter(llm_client, cache)
    result = await writer.create_column("æœºå™¨å­¦ä¹ ç®—æ³•è¯¦è§£")
    
    ColumnExporter.export_to_files(result)

if __name__ == "__main__":
    asyncio.run(cached_example())
```

### 6.4 äººå·¥å¹²é¢„æ¨¡å¼

```python
async def interactive_example():
    """äººå·¥å¹²é¢„æ¨¡å¼ç¤ºä¾‹"""
    
    llm_client = LLMClient(model="gpt-4")
    
    writer = InteractiveColumnWriter(
        llm_client,
        interactive_mode=True
    )
    
    result = await writer.create_column("Webå¼€å‘æœ€ä½³å®è·µ")
    ColumnExporter.export_to_files(result)

if __name__ == "__main__":
    asyncio.run(interactive_example())
```

### 6.5 å¤šæ¨¡å‹åä½œ

```python
async def multi_model_example():
    """å¤šæ¨¡å‹åä½œç¤ºä¾‹"""
    
    # ä¸åŒä»»åŠ¡ä½¿ç”¨ä¸åŒæ¨¡å‹
    planner_llm = LLMClient(model="gpt-4", temperature=0.8)    # è§„åˆ’ç”¨é«˜åˆ›é€ æ€§
    writer_llm = LLMClient(model="gpt-4", temperature=0.7)     # å†™ä½œç”¨ä¸­ç­‰åˆ›é€ æ€§
    reviewer_llm = LLMClient(model="gpt-4", temperature=0.3)   # è¯„å®¡ç”¨ä½åˆ›é€ æ€§ï¼ˆä¸¥æ ¼ï¼‰
    
    writer = MultiModelColumnWriter(
        planner_llm=planner_llm,
        writer_llm=writer_llm,
        reviewer_llm=reviewer_llm
    )
    
    result = await writer.create_column("äº‘è®¡ç®—æ¶æ„è®¾è®¡")
    ColumnExporter.export_to_files(result)

if __name__ == "__main__":
    asyncio.run(multi_model_example())
```

### 6.6 å¢é‡å¼å†™ä½œ

```python
async def incremental_example():
    """å¢é‡å¼å†™ä½œç¤ºä¾‹"""
    
    llm_client = LLMClient(model="gpt-4")
    
    writer = IncrementalColumnWriter(
        llm_client,
        checkpoint_file="my_column_checkpoint.json"
    )
    
    try:
        result = await writer.create_column("åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡")
        ColumnExporter.export_to_files(result)
    except KeyboardInterrupt:
        print("\nâ¸ï¸  å·¥ä½œå·²æš‚åœï¼Œè¿›åº¦å·²ä¿å­˜")
        print("   ä¸‹æ¬¡è¿è¡Œå°†ä»æ–­ç‚¹ç»§ç»­")

if __name__ == "__main__":
    asyncio.run(incremental_example())
```

### 6.7 å®Œæ•´çš„ç”Ÿäº§ç¯å¢ƒç¤ºä¾‹

```python
import asyncio
import logging
from typing import Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('column_writer.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

async def production_example():
    """ç”Ÿäº§ç¯å¢ƒå®Œæ•´ç¤ºä¾‹"""
    
    try:
        # 1. åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆæ”¯æŒé‡è¯•å’Œé”™è¯¯å¤„ç†ï¼‰
        llm_client = LLMClient(
            model="gpt-4",
            temperature=0.7,
            max_tokens=4000,
            retry_times=3,
            timeout=60
        )
        
        # 2. é…ç½®å†™ä½œç³»ç»Ÿ
        config = {
            'approval_threshold': 75,
            'revision_threshold': 60,
            'max_depth': 3,
            'enable_parallel': False  # ç”Ÿäº§ç¯å¢ƒå»ºè®®å…³é—­å¹¶è¡Œä»¥ä¾¿è°ƒè¯•
        }
        
        # 3. åˆ›å»ºç¼“å­˜å’Œå†™ä½œç³»ç»Ÿ
        cache = ContentCache(backend='redis')  # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨Redis
        writer = CachedColumnWriter(llm_client, cache)
        
        # æˆ–ä½¿ç”¨å¢é‡å¼å†™ä½œå™¨
        # writer = IncrementalColumnWriter(llm_client, checkpoint_file="checkpoint.json")
        
        # 4. åˆ›å»ºä¸“æ 
        logger.info("å¼€å§‹åˆ›å»ºä¸“æ ")
        result = await writer.create_column(
            main_topic="å¾®æœåŠ¡æ¶æ„å®æˆ˜æŒ‡å—"
        )
        
        # 5. å¯¼å‡ºç»“æœ
        output_dir = f"output_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        ColumnExporter.export_to_files(result, output_dir=output_dir)
        logger.info(f"ä¸“æ å·²å¯¼å‡ºåˆ°: {output_dir}")
        
        # 6. å‘é€é€šçŸ¥ï¼ˆå¯é€‰ï¼‰
        await send_completion_notification(result, output_dir)
        
        return result
        
    except Exception as e:
        logger.error(f"ä¸“æ åˆ›å»ºå¤±è´¥: {e}", exc_info=True)
        # è¿™é‡Œå¯ä»¥æ·»åŠ å‘Šè­¦é€»è¾‘
        raise

async def send_completion_notification(result: Dict[str, Any], output_dir: str):
    """å‘é€å®Œæˆé€šçŸ¥"""
    stats = result['statistics']
    quality = result['quality_report']
    
    message = f"""
    ä¸“æ åˆ›å»ºå®Œæˆï¼
    
    æ ‡é¢˜: {result['column_info']['title']}
    æ–‡ç« æ•°: {stats['total_articles']}
    æ€»å­—æ•°: {stats['total_words']:,}
    å¹³å‡åˆ†æ•°: {quality['average_score']:.1f}/100
    è¾“å‡ºç›®å½•: {output_dir}
    """
    
    # è¿™é‡Œå¯ä»¥æ¥å…¥é‚®ä»¶ã€é’‰é’‰ã€ä¼ä¸šå¾®ä¿¡ç­‰é€šçŸ¥æ¸ é“
    logger.info(message)

if __name__ == "__main__":
    asyncio.run(production_example())
```

---

## ä¸ƒã€æ€»ç»“

### 7.1 ç³»ç»Ÿç‰¹ç‚¹

1. **æ ‘å½¢é€’å½’æ¶æ„**ï¼šè‡ªç„¶æ”¯æŒå†…å®¹çš„å±‚æ¬¡åŒ–ç»„ç»‡
2. **æ™ºèƒ½è¯„å®¡æœºåˆ¶**ï¼šè¯„åˆ† + è¯¦ç»†åé¦ˆ + ä¿®æ”¹å»ºè®®
3. **ä¸€æ¬¡ä¿®æ”¹ç­–ç•¥**ï¼šé¿å…åå¤è¿­ä»£ï¼Œæé«˜æ•ˆç‡
4. **å®Œæ•´è´¨é‡è¿½è¸ª**ï¼šè®°å½•è¯„å®¡åˆ†æ•°ã€ä¿®æ”¹å†å²ã€ç»Ÿè®¡æ•°æ®
5. **çµæ´»æ‰©å±•æ€§**ï¼šæ”¯æŒå¹¶è¡Œã€ç¼“å­˜ã€äººå·¥å¹²é¢„ç­‰å¤šç§æ¨¡å¼

### 7.2 æœ€ä½³å®è·µ

1. **åˆç†è®¾ç½®é˜ˆå€¼**ï¼š
   - é€šè¿‡é˜ˆå€¼ï¼ˆ75åˆ†ï¼‰ï¼šå¹³è¡¡è´¨é‡å’Œæ•ˆç‡
   - ä¿®æ”¹é˜ˆå€¼ï¼ˆ60åˆ†ï¼‰ï¼šåŒºåˆ†ä¿®æ”¹å’Œé‡å†™

2. **å±‚çº§æ·±åº¦æ§åˆ¶**ï¼š
   - å»ºè®®æœ€å¤§æ·±åº¦ä¸º3å±‚
   - é¿å…è¿‡åº¦ç»†åˆ†å¯¼è‡´å†…å®¹ç¢ç‰‡åŒ–

3. **å¹¶è¡Œå¤„ç†è°¨æ…**ï¼š
   - å¼€å‘æµ‹è¯•é˜¶æ®µå»ºè®®å…³é—­
   - ç”Ÿäº§ç¯å¢ƒæ ¹æ®APIé™åˆ¶å†³å®š

4. **ç¼“å­˜ç­–ç•¥**ï¼š
   - å¼€å‘é˜¶æ®µä½¿ç”¨å†…å­˜ç¼“å­˜